\section{\textbf{Question:} What is this thesis about?}

\newthought{\textbf{Reply:} This thesis is about mathematically approximating natural language text using string diagrams}

\marginnote{
Let's say that \textbf\emph{{the meaning of text is how it updates a model.}} So we start with some model of the way things are.
\[\scalebox{0.75}{\tikzfig{intro/model}}\]
Text updates that model; like a gate updates the data on a wire.
\[\scalebox{0.75}{\tikzfig{intro/model2}}\]
Text is made of sentences; like a circuit is made of gates and wires.
\[\scalebox{0.75}{\tikzfig{intro/model3}}\]
Let's say that \textbf{\emph{The meaning of a sentence is how it updates the meanings of its parts.}} As a first approximation, let's say that the \emph{parts} of a sentence are the nouns it contains or refers to. Noun data is carried by wires. Collections of nouns are related by gates.
\[\scalebox{0.5}{\tikzfig{intro/model4}}\]
Gates can be related by higher order gates.
\[\scalebox{0.5}{\tikzfig{intro/model5}}\]
Higher order gates may be implemented as gates that modify the parameters of other gates.
\[\scalebox{0.5}{\tikzfig{intro/model6}}\]
Every gate corresponds to a \emph{content word} -- a word with a dictionary meaning.
\[placeholder\]
Grammar, and \emph{function words} -- words that operate on meanings -- are absorbed by the geometry of the diagram.
\[placeholder\]
Text diagrams like the above are compositional blueprints that may be instantiated by classical or quantum computers. Since we know how grammar composes meanings in language, we can quotient out grammar using these formal diagrams. This process turns big black boxes into composites of small black boxes, which is a happy middle ground for humans and computers: smaller pieces for machines to learn representations for, and easy-to-reckon representations for humans.
}

\newthought{\textbf{Point of information:} What do you mean by natural language?}

Natural language is \emph{the} human superpower, the foundation of all of our collective achievements and mistakes as a species. By \emph{natural language} I mean a non-artificial human language that some child has grown up speaking. English is a natural language, while Esperanto and Python are constructed languages. If you are still reading then you probably know a thing or two already about natural language. Insofar as there are rules for natural languages, it is probable that like most natural language users, you obey the rules of language intuitively without knowing what they are formally; for example while you may not know what adpositions are, you know where to place words like \texttt{to}, \texttt{for}, \texttt{of} in a sentence and how to understand those sentences. At a more complex level, you understand idioms, how to read between the lines, how to flatter, insult, teach, promise, wager, and so on. A theory of language is a theory of everything that can be theorised.

\newthought{\textbf{Point of information:} What are string diagrams?}

String diagrams are a heuristically natural yet mathematically formal syntax for representing complex, composite systems. I will define them formally and demonstrate their use in Section \ref{}. I say \emph{mathematically} formal to emphasise that string diagrams are not merely heuristic tools backed by a handbook of standards decided by committee: they are unambiguous mathematical objects that you can bet your life on. [Cites]\\

Just as crustaceans independently converge to crab-like shapes by what is called \emph{carcinisation}, formal notation for formal theories of "real world" problem domains undergo "string diagrammatisation". Why should that be so? Our best formal theories of the "real world" treat complexity as the outcome of composing simple interacting parts; perhaps nature really works that way, or we cannot help but express ourselves using composition.\\

When one has many different processes sending information to each other via channels, it becomes tricky to keep track of all the connections using one-dimensional syntax; if there are $N$ processes, there may be on the order of $\mathcal{O}(N^2)$ connections, which quickly becomes unmanageable to write down in a line, prompting the development of indices in notation. In time, probably by doodling a helpful line during calculation to match indices, connected indices become wires, and string diagrams are born.

\section{\textbf{Question:} Why study language when Large Language Models can already do XYZ?}

Just as Camus treats suicide as the fundamental question, the first question we must address is why it is worth continuing, why this thesis is worth writing, why this topic is worth attention. I will start with the issue of practical value because practical people are impatient, and luckily we only need to address a single, though devastating, question.\\

Let me outline the terms and stakes of the question. Large Language Models, at the time of writing, are programs trained -- using a lot of data and a lot of compute time -- to predict the next word in text []. This sounds unimpressive, but it is enough to tell and explain jokes [], pass the SAT [], score quite well on an IQ test for humans [], ... While there remain limitations, such as tendency to hallucinate facts [], (ironically, for a computer) bad arithmetic [], sycophancy []... it is evident to all observers that this is an important technology, for several reasons.\\
First, it is a civilisational milestone technology; a force-multiplication tool for thought built from data and compute in the silicon age may have comparably broad, deep, and lasting impact to the conversion of abundant chemical fuel to physical energy by steam engines in the industrial revolution [].\\
Second, LLMs represent a paradigm shift for humanity because they threaten our collective self-esteem, in a more pointed manner than losing at chess [] or Go [] to a computer; to borrow a line of thinking from [], LLMs demonstrate that language and (the appearance of) complex thought that language facilitates is not a species-property for humans, and this stings on par with Darwin telling us we are ordinary animals like the rest, or Galileo telling us our place in the universe is unremarkable.\\
Third is that LLMs represent the latest and greatest case study of the bitter lesson []. The tragedy goes like this: there a group of people who investigate language -- from syntax and semantics to pragmatics and analogies and storytelling and slang -- who treat their subject with formal rigour and have been at it for many centuries longer than even the idea of computers. Their role in the story of LLMs is remarkable because it doesn't exist. They were the only qualified contestants in a "let's build a general-purpose language machine" competition, and they were a no-show. Now the farce: despite the fact that all of our understanding and theories were left out of the process, the machine is not only built but also far exceeds anything we know how to build in a principled way out of our current understanding. That is the bitter lesson: dumb methods that use a lot of data and compute outperform clever design and principled understanding.\\

I will note in passing that I have an ugly duckling problem, in that I am not strictly aligned with machine learning, nor linguists broadly construed, nor mathematical linguists in particular. I am unfortunately placed in that I feel enough affinity to have defensive instincts for each camp, but I am distanced enough from each that I am sure to suffer attacks from all sides. Perhaps a more constructive metaphor than war is that I am writing in a cooperative spirit between domains, or that I am an arbitrageur of ideas between them. With that in mind, I am for the moment advocating on behalf of pen-and-paper-and-principles linguists in formulating a two-part reply to the devastating question. First a response that answers with practical values in mind, and then a response that asserts and rests upon the distinct values of linguists.

\newthought{\textbf{Reply:} We want economy, generality, and safety for language models, and we can potentially do that with no tradeoffs.}

Both camps stand to benefit from interaction. For linguists, LLMs are a rich source of empirical data for linguistic issues. For example, there is fuzzy and widely-held notion that language must somehow be intimately related to reasoning and cognition, or that all of these things are inseparably clustered under the name of "intelligence". An observation from LLMs that sheds light on this notion is that when a language model becomes sophisticated enough, it can employ chain-of-thought [] to bootstrap reasoning ability. Perhaps more directly, the ability of LLMs to pass textual equivalents of Raven's progressive matrices [] -- a common form of IQ test intended to measure generalisation ability -- is remarkable considering that the model had likely never seen analogous training data for that task, which hints at an overlap between the 'narrow' task of predicting linguistic output and the very general task of pattern recognition.\\

\marginnote{As a historical aside [], there is an aspect of genuine scientific surprise that text-prediction can do this kind of magic. Computational linguistics began in a time when compute was too scarce to properly attempt rationalist, knowledge-based and theoretically-principled approaches to modelling language. Text-prediction -- using Markov n-grams [] -- as a task arose from a deliberate pursuit of "low-hanging fruit" as a productive and knowledge-lean alternative to doing nothing in an increasingly data-rich environment. Some observers [] expressed concern that all this fruit would be picked bare in a generation. In contrast, a knowledge-lean bullish sentiment arose [] that cranking the handle to increase the size of the computer and the amount of training data would eventually lead to general artificial intelligence. The battle lines were drawn against the knowledge-based bears who held that qualititative improvements necessitated more sophisticated and theoretically-informed approaches to tasks and problems []. While the epistemology of Data Science [] is a topic in its own right, here is a caricature [] that summarises the opposing positions at a glance:

\[moar layers\]

What is funnier than the comic is that the jesters were right about only having to crank the handle. To the credit of the bears, it may still be the case that the performance of current LLMs is a Chinese Room [] phenomenon (or, in its more modern incarnation, a hyperintelligent octopus []) in that there is nothing resembling cognition under the hood. So it may be that there are some qualitative abilities -- say, indefinite recursive nesting in text -- that are unreachable by, say, transformers, no matter how big they get. However, we have to entertain the possibility that those limits may be beyond human ability to discern; that is, even though LLMs may not \emph{think} in any meaningful sense, they can fool us that they do, no matter what methods of testing we apply.
}

There is one linguistics-adjacent issue which has in a sense become considerably more severe given what we observe from LLMs -- the 'poverty of the stimulus' -- and this is buried treasure for the AI-scientist. In short, this named problem is the observation that humans learn language despite having very little training data, in comparison to the complexity of the learned structure. It is on the basis of this observation that Chomsky posits [] that language is an innate human faculty, the development of which is less like effortfully going to the gym and more like effortlessly growing arms you were meant to have. The explanation goes like this: we can explain how a complex structure like grammar gets learnt from a small amount of data if everyone shares an innate Universal Grammar with a small number of free parameters. On other accounts, there is no such monolithic faculty of grammar in our brains or minds [], but whatever the intermediate mechanism is, the point is that we humans get some input data, that data interacts with the mechanism in some way, and then we know a language. So, if there is a language-entity that is human-comparable in competence, we can make a proxy estimate of how much work the intermediate mechanism is doing by comparing the difference in how much data and compute is required for both the human and for the machine to achieve language-competence. Humans get about 1.5 megabytes of data [], 90 billion neurons [], and X calories for thinking. PaLM -- which is by its creators' account the first language model to be able to reason and joke purely on the basis of linguistic ability and without special training [] -- required Z of data, 540 billion neurons [], and Z calories for training. Taking the product of those input costs, whatever the human mechanism is, it is responsible for an order of magnitude in efficiency, give or take an order of magnitude \emph{of orders of magnitude}. If it is worth hunting a fraction of a percent of improvement on a benchmark, forget your hares, here is a stag.\\

\newthought{\textbf{Interjection:} The human mechanism cannot be worth implementing in silico because that requires subject-matter expertise, and that goes against the bitter lesson.}

It is not totally fair on my part to cast the objector as a cargo cultist in this way, as if subject-matter expertise ought to be superstitiously avoided, but the bitter lesson is so harsh and often-enough repeated that this viewpoint is worth addressing proactively. The caveat that saves us is that the curse of expertise applies only to the object-language of the problem to be solved, not model architectures. That is, qualitative improvements in problem-solving ability rarely if ever arise from encoding expert knowledge of the problem domain. Instead -- and we see this historically [deep, decision, qlearn, GAN, transformers] -- these improvements come from architectural innovations, which means altering the parts and internal interactions of a model: changing \emph{how} it thinks rather than \emph{what} it thinks. These structural changes are motivated by understandings (at varying degrees of formality) of the "geometry of the problem" [geometric DL]. The value proposition here is that with an appropriate mathematical lingua franca for structure, composition, and interaction (Category Theory), we can mindfully design rather than stumble upon the "meta-methods" Sutton calls for, allowing experts to encode \emph{how} they think and discover rather than \emph{what}.\\

So how do we hunt the stag? What do we know about how the mechanism between our ears works with language? The good news is that the chief methodology of armchair introspection is egalitarian and democratic. The bad news is that it is also anarchistic and hard-by-proximity; we are like fishes in water, and it is hard for fishes to characterise the nature of water. So the happy observations are difficult to produce and easily verified, and that means there just a few that we know of that are are unobjectionably worth taking into account. One, or \emph{the} such observation is compositionality, or systematicity -- the concepts differ slightly or not at all depending on where you are from academically. [Frege]'s initial conception of compositionality was borne of meditations on language, and states that a whole is the sum of its parts; the more that sounds like a contentless tautology, the cleverer Frege is for spotting it. Later conceptions of compositionality [], the most notable deviation arising from meditations on quantum theory, are the same as the original, modulo variations on the formal definitions of parts and the method of summation. Systematicity [Fodor] refers to when a system can (generate/process) infinitely many (inputs/outputs/expressions) using finite (means/rules/pieces) in a "consistent" (or "systematic") manner; the more contentless and circular that sounds, the cleverer Fodor is for expressing it. Like pornography, examples are easier than definitions; we know finitely many words but we can produce and understand infinitely many texts; we can make infinitely many lego sculptures out of finitely many types of pieces; we can describe infinite groups and other mathematical structures using finitely many generators and relations. The last example, that of "finitely presented structures" in mathematics, is probably the closest formal incarnation of systematicity. The only way we know how to achieve systematicity in practice is composition. In the practical domain of computers, systematicity is synonymous with programmability and expressibility.\\

\newthought{\textbf{Interjection:} GOFAI called and they want their symbolic-compositional approaches back. Can't you see that connectionist methods have already won?}

The characterisation of a disgruntled AI-practitioner above is unfair mostly because the symbolic/connectionist divide is so settled [] that essentially no practitioner today would refer to their own methods as "connectionist", and symbolic-adjacent approaches [] are small subfields, not competitors. Moreoever, hostility to symbolic approaches is a stance espoused by some of the leading lights of modern machine learning []. This stance is worth elaborating and steelmanning for pen-and-paper-people in the context of language. First, linguistic phenomena are nebulous [] -- the boundary of a simile is like that of a cloud, not sharp like the boundary of a billiard ball. Second, linguistic phenomena are complex, dynamic, and multifactorial: there are so many interacting mechanisms and forces in the production and comprehension of language that even if we do have crisp mathematical models for all the constituent processes we are still left with something computationally irreducible []. The latter term refers to a special kind of computational difficulty which is best understood by example. We have a closed-form mathematical expression to shortcut the computation of the evolution of a system of two point masses under gravity, but we have no such shortcut for the three-body problem; the best we can do is simulate the system's evolution, and the lesson is that even for very simple systems, it is possible that no amount of causal-mechanistic understanding will simplify compututational simulation. These two points together weakly characterise the kinds of problem domains where machine learning shines []. It is just a fact that LLM outputs today conform to any sensible understanding of syntax, semantics, pragmatics, conversational implicature, and whatever else we have theorised. It is just a fact that they produce better poetry and humor than anything we could explicitly program according to our current understanding. It is also a fact that they will only get better from here.\\

So, as far as practical language applications are concerned, the only theories that are nonstarters have to bring something to the table. To borrow terms from concurrency, there is already plenty of liveness, what is needed is more safety; liveness is when the program does something good, and safety is a guarantee it won't do something bad. For example; there is ongoing work in integrating LLMs with stuctured databases for uses where facts and figures matter []; there is still a need for safeguards to prevent harmful outputs [] and adversarial attacks like prompt injection []; while LLMs give a very convincing impression of reasoned thought, we would like to be sure if ever we decide to use such a machine for anything more than entertainment, like deciding on a medical course of treatment [] or making decisions with financial consequences []. The good news is that symbolic-compositional theories are the right shape for safety concerns, because they can be picked apart and reasoned about []. It is clear however that symbolic-compositional approaches by themselves are nowhere near achieving the kind of liveness LLMs have. Therefore, the direction of progress is synthesis.\\

The investigation of the common ground between symbolic-composition and connectionism takes on, I suggest, essentially two, dual forms. The first kind uses connectionist methods to simulate symbolic-composition. The second kind is the inverse, where connectionist architectures are organised and reasoned by symbolic-compositional means. Some examples of the first include implementing data structures as operations on high-dimensional vectors, taking advantage of the idiosyncrasies of linear algebra in very high dimension [], or work that explores how the structure of word-embeddings in latent space encode semantic relationships between tokens []. Some examples of the second include reasoning about the capability of graph neural networks by identifying their underlying compositional structure [,], or architectures explicitly designed to instantiate symbolic-compositional structures using neural nets as constituent parts, such as GANs [] and gradient boosted decision trees []. The work in this thesis builds upon a research programme -- DisCoCat, elaborated in Section \ref{} -- which lies somewhere in the middle of the duality. It is, to the best of my knowledge, the only approach that explicitly incorporates mathematically rigourous compositional structures with data-driven learning methods. Fortifying this bridge across the aisle requires a little give from both sides; I ask only that reader entertain some pretty string diagrams.

\newthought{\textbf{Interjection:} String diagrams are just graphs! Plus, they don't look very complicated; they barely even look like serious mathematics.}

Yes and no! This point is best communicated by a mathematical koan. Consider the following game between two players, you and me. There are 9 cards labelled 1 through 9 face up on the table. We take turns taking one of the cards. The winner is whoever first has three cards in hand that sum to 15, and the game is a draw if we have taken all the cards on the table and neither of us have three cards in hand that sum to 15. I will let you go first. Can you guarantee that you won't lose? Can you spell out a winning strategy? If you have never heard this story, give it an honest minute's thought before reading on.\\

The usual response is that you don't know a winning strategy. I claim that you probably do. I claim that even a child knows how to play adeptly. I'll even wager a drink that you have played this game before. The game is Tic-Tac-Toe, also known as Naughts-and-Crosses: it is possible to arrange the cards in a 3-by-3 magic square, such that every column, row, and diagonal sums to 15.\\

What is the lesson here? On the surface, here is an example of two representations of the same platonic mathematical object. These representations are the same as far as a computer or a formal symbol-pusher is concerned. These representations make a world of difference to a human native of meatspace. Deeper, the lesson is that representations matter, because they generalise differently. Tic-Tac-Toe is in the same family as Connect-4 or 5-in-a-row on an unbounded grid. The game with numbered cards generalises to different variants of Nim. That they coincide in one instance is a fork in the path. In the same way, viewing string diagrams as "just graphs" is taking the wrong path, just as it would be a mistake to dismiss graphs as "just sets of vertices and edges". String diagrams are indeed "just" a special family of graphs, just as much as prime numbers are special integers and analytic functions are special functions.

\marginnote{The deeper objection here is that diagrams are not serious mathematics. Later I will give ample space to show how they are serious, but the reasons behind this rather common prejudice are worth elaborating. This is the wound Bourbaki has inflicted. Nicolas Bourbaki is a pseudonym for a group of French mathematicians, who wrote a highly influential series of textbooks. It is difficult to overstate their influence. The group was founded in the aftermath of the First World War, around the task of writing a comprehensive and rigourous foundations of mathematics from the ground up. The immediate \emph{raison-d'\^{e}tre} for this project was that extant texts at the time were outdated, and the oral tradition and living history of mathematics in institutions of learning were decimated by the deaths of mathematicians at war. In a broader historical context [], Bourbaki was a reactionary response to the crisis in the foundations of mathematics at the beginning of the century, elicited by Russell's paradox. Accordingly, their aims were rationalist, totalitarian, and high-modernist [], favouring abstraction and disdaining visualisation, in line with their contemporary artistic and musical fashions. Consequently, Bourbaki's style of mathematical exposition is evolved form of Euclid's Definition-Proposition-Theorem that eschews intuition and example, a format pretending at timelessness that requires years of initiation to effectively read and write, and remains \emph{de rigeur} for rigour today in dry mathematics textbooks. The deeper objection arises from the supposition that serious mathematics ought to look arcane and difficult, as most mathematics exposition after Bourbaki is. The reply is that it need not be so, and that it was not always so! The Bourbaki format places emphasis and prestige upon the deductive activity that goes into proving a theorem, displacing other aspects of mathematical activity such as constructions, algorithms, and taxonomisation []. In this sense, this thesis is anti-Bourbaki mathematical activism, in that the nebulous subject matter of natural language does not lend itself well to theorems, but it is a happy muse for constructions and the mathematical play that follows.}
