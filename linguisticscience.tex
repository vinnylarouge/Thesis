\section{Is formal linguistics a science? If not, could it be?}

It may seem tempting at first to rescue the dignity and importance of formal semantics (in all its forms, present work included) by appeal to some kind of scientific process, but I argue that this is either scientism, or else aspiring to this stance seriously means at minimum doing formal linguistics with mathematical methods similar to what I use here, and taking machine learning seriously. First I'll sketch some goodmaking properties of theories. Then, I'll sketch out goodmaking properties of theories as a human activity. Then I will show that in the particular case of formal linguistics, these goodmaking properties are in tension with one another, and how this tension can only be resolved by bringing machine learning into the fold, and that would entail the use of similar mathematical methods to those used here.

\newthought{Goodmaking properties of a theory}

Let's suppose that formal linguistics aspires to be Science, whatever that means. Just to get some terminology on the board, bodies of formal theories that aspire to the status of science can be roughly split into ideal-type and empirical-type, depending on their relationship to the empirical phenomena. Insofar as theories undergo a constrained optimisation of generality, precision, and realism [CITE levins], in ideal-type theories generality is favoured, and in empirical-type the latter. It seems agreeable for the purposes of this discussion that the triad of generality, precision and realism are jointly goodmaking properties of a theory; consider that each property on its own can't be enough, as what good is a perfectly general but totally unrealistic theory? A consequence of this observation is that no matter whether a theory leans ideal-type or empirical-type at a particular moment, it is only good insofar as it satisfies its complementary goodmaking properties, and it could be improved or made better if it, over time, grew to become more like the other type of theory. Concretely: ideal-type theories are good to the extent that they purport to currently or eventually capture empirical data more precisely, and empirical-type theories are good to the extent of their current or eventual breadth of coverage. This setup is a decent intuition pump; the opposing pressures for types of theory to become more like one another induce the dynamic evolution of a theory towards better versions of itself.

\newthought{The human aspect}

The triad of generality, precision and realism are not quite sufficient: we also need simplicity, particularly of an anthropomorphic and prosocial kind that promotes a process of inquiry. To sketch this out via negativa, here are some examples of things that we may not want to count as good theories even if they do satisfy the triad:

\begin{itemize}
\item{A large language model, used as an oracle to answer star-unstar questions. This satisfies the triad, but it is not simple.}
\item{The same large language model fed through a powerful compression algorithm: this description may be simple according to Kolmogorov complexity.}
\item{A person, used as an oracle to answer star-unstar questions consistently, but unable to articulate why.}
\item{A complex algorithm }
\end{itemize}

or else we might be forced to conclude that putting an LLM through a powerful compression algorithm somehow yields a good theory. So it's not Occam's razor or Kolmogorov complexity that I am trying to articulate here...

\newthought{Formal linguistics as an ideal-type theory}

...

\newthought{Formal linguistics as empirical-type theory}

If we want to say that formal linguistics is an empirical science, then we purport a standard of searching for explanatory principles for empirical data. The prototype is when a briefly stated principle $P$ within formal framework $F$ accounts for some data $D$ in the remit of the phenomena $X$, hence principle $P$ constitutes an "understanding" of phenomena $X$. I want to grant a narrow conception of "understanding" to precisely that sort of briefly communicable $P$ couched within a $F$, and I will limit consideration to good-faith theory, where for instance nobody is touting the simplicity of a principle $P$ while trying to hide the complexity of $F$ and the well-definedness of $X$. Even granting all this, many factors still imperil the inference to "$P$ constitutes an understanding of $X$", for example: the complexity of $P$ and $F$, the adequacy of $F$ as a model of $X$, and essentially any aspect of the supporting empirical data, such as its origin, quantity, and quality. As a general and easily observable rule, for any given complexity of framework $F$, breadth and depth of data of $X$ is at odds with sharp principles $P$, and more generally tradeoffs on this pareto front of imperilling factors is decided by extra-rational values and priorities. Whatever that priority in the aggregate is called, it manifests in contemporary formal semantics as a revealed preference for simple principles $P$ and simple building blocks for baroque frameworks $F$, which results in a tendency to limit consideration to armchair-farmed small data of narrowly-defined $X$. This situation produces an epistemic hazard characteristic of fields where people who know a little maths think that they can swallow the ocean of the real world: the theory and data originate from the same armchair, so the data is more an appendix of $F$ than anything to do with $X$ "out there", and the result is that all talk of principle $P$ and the machinations of $F$ constitutes only a self-referential understanding which is conflated with knowledge of the world. The way out of course is to go broad and deep and rich with data, and with our current infrastructures for harvesting and processing human judgement data and everything else besides, not to expand in this way is not defensibly a matter of unavailability of access or anything that cannot be overcome. To actually interact via data with the real world, something about $P$ or $F$ has to give. If we are willing to give up on simple principles $P$, we lose something human about science, and we also have no need of truth-conditions: of course the truth-conditional approach is adequately expressive for general computation, so it is logically possible to expand $F$ to eventually account for all the data $X$ that a typical large language model is trained on, and this procedure would be exactly machine learning, except over a hypothesis space of frameworks $F$ and done laboriously by hand. On the other hand, keeping principles $P$ simple and accounting for big data of $X$ forces more abstract $F$, and that is what the use of category theory enables: the notion of formal linguistics in this work is one that is big-data compatible while retaining structural insights. I personally prefer to avoid the issue of scientific or empirical obligations altogether by considering all formal (i.e. mathematical) linguistics (present work included) to be a special-interest hobby.