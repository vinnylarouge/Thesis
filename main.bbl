\begin{thebibliography}{10}

\bibitem{bastian_google_2022}
Matthias Bastian.
\newblock Google {PaLM}: {Giant} language {AI} can explain jokes, April 2022.

\bibitem{bender_climbing_2020}
Emily~M. Bender and Alexander Koller.
\newblock Climbing towards {NLU}: {On} {Meaning}, {Form}, and {Understanding}
  in the {Age} of {Data}.
\newblock In {\em Proceedings of the 58th {Annual} {Meeting} of the
  {Association} for {Computational} {Linguistics}}, pages 5185--5198, Online,
  2020. Association for Computational Linguistics.

\bibitem{chomsky_new_2000}
Noam Chomsky.
\newblock {\em New {Horizons} in the {Study} of {Language} and {Mind}}.
\newblock Cambridge University Press, Cambridge, 2000.

\bibitem{chowdhery_palm_2022}
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra,
  Adam Roberts, Paul Barham, Hyung~Won Chung, Charles Sutton, Sebastian
  Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez,
  Abhishek Rao, Parker Barnes, Yi~Tay, Noam Shazeer, Vinodkumar Prabhakaran,
  Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob
  Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm
  Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia,
  Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David
  Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David
  Dohan, Shivani Agrawal, Mark Omernick, Andrew~M. Dai,
  Thanumalayan~Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica
  Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi
  Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei,
  Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel.
\newblock {PaLM}: {Scaling} {Language} {Modeling} with {Pathways}, October
  2022.
\newblock arXiv:2204.02311 [cs].

\bibitem{church_pendulum_2011}
Kenneth Church.
\newblock A {Pendulum} {Swung} {Too} {Far}.
\newblock {\em Linguistic Issues in Language Technology}, 6, October 2011.

\bibitem{floridi_fourth_2014}
Luciano Floridi.
\newblock {\em The {Fourth} {Revolution}: {How} the {Infosphere} is {Reshaping}
  {Human} {Reality}}.
\newblock OUP Oxford, New York ; Oxford, June 2014.

\bibitem{hendrycks_measuring_2021}
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric
  Tang, Dawn Song, and Jacob Steinhardt.
\newblock Measuring {Mathematical} {Problem} {Solving} {With} the {MATH}
  {Dataset}, November 2021.
\newblock arXiv:2103.03874 [cs].

\bibitem{herculano-houzel_remarkable_2012}
Suzana Herculano-Houzel.
\newblock The remarkable, yet not extraordinary, human brain as a scaled-up
  primate brain and its associated cost.
\newblock {\em Proceedings of the National Academy of Sciences of the United
  States of America}, 109 Suppl 1(Suppl 1):10661--10668, June 2012.

\bibitem{joyal_geometry_1991}
André Joyal and Ross Street.
\newblock The geometry of tensor calculus, {I}.
\newblock {\em Advances in Mathematics}, 88(1):55--112, July 1991.

\bibitem{khan_what_2023}
Tabarak Khan.
\newblock What are tokens and how to count them?, 2023.

\bibitem{lane_categories_2010}
Saunders~Mac Lane.
\newblock {\em Categories for the {Working} {Mathematician}: 5}.
\newblock Springer, New York, NY, 2nd ed. 1978. softcover reprint of the
  original 2nd ed. 1978 edition edition, November 2010.

\bibitem{maclane_natural_1963}
Saunders MacLane.
\newblock Natural {Associativity} and {Commutativity}.
\newblock {\em Rice Institute Pamphlet - Rice University Studies}, 49(4),
  October 1963.
\newblock Accepted: 2011-11-08T19:13:47Z Publisher: Rice University.

\bibitem{mcshane_linguistics_2021}
Marjorie McShane and Sergei Nirenburg.
\newblock {\em Linguistics for the {Age} of {AI}}.
\newblock March 2021.

\bibitem{mollica_humans_2019}
Francis Mollica and Steven~T. Piantadosi.
\newblock Humans store about 1.5 megabytes of information during language
  acquisition.
\newblock {\em Royal Society Open Science}, 6(3):181393, March 2019.

\bibitem{narang_pathways_2022}
Sharan Narang and Aakanksha Chowdhery.
\newblock Pathways {Language} {Model} ({PaLM}): {Scaling} to 540 {Billion}
  {Parameters} for {Breakthrough} {Performance}, 2022.

\bibitem{openai_chatgpt_2022}
{OpenAI}.
\newblock {ChatGPT}: {Optimizing} {Language} {Models} for {Dialogue}, November
  2022.

\bibitem{searle_minds_1980}
John~R. Searle.
\newblock Minds, brains, and programs.
\newblock {\em Behavioral and Brain Sciences}, 3(3):417--424, September 1980.
\newblock Publisher: Cambridge University Press.

\bibitem{selinger_survey_2010}
Peter Selinger.
\newblock A survey of graphical languages for monoidal categories.
\newblock volume 813, pages 289--355. 2010.
\newblock arXiv:0908.3347 [math].

\bibitem{sutton_bitter_2019}
Richard Sutton.
\newblock The {Bitter} {Lesson}, 2019.

\bibitem{teddy_teddynpc_i_2022}
{teddy [@teddynpc]}.
\newblock I made {ChatGPT} take a full {SAT} test. {Here}'s how it did:
  https://t.co/{734sPFU3HY}, December 2022.

\bibitem{thompson_gpt-35_2022}
Alan~D. Thompson.
\newblock {GPT}-3.5 {IQ} testing using {Raven}’s {Progressive} {Matrices},
  2022.

\bibitem{tom_goldstein_tomgoldsteincs_training_2022}
{Tom Goldstein [@tomgoldsteincs]}.
\newblock Training {PaLM} takes 3.2 million kilowatt hours of power. {If} you
  powered {TPUs} by riding a bicycle, and you pedaled hard (nearly 400 watts),
  it would take you 1000 years to train {PaLM}, not including bathroom breaks.
  {In} that time, you'd make 320 trips around the globe!, July 2022.

\bibitem{vaswani_attention_2017}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention {Is} {All} {You} {Need}, December 2017.
\newblock arXiv:1706.03762 [cs].

\end{thebibliography}
