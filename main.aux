\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {0}Synopsis}{7}{chapter.0}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{joyal_geometry_1991,joyal_geometry_nodate,maclane_natural_1963,lane_categories_2010,selinger_survey_2010}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Let's say that \textbf  \emph  {{the meaning of text is how it updates a model.}} So we start with some model of the way things are, modelled as data on a wire.}}{8}{section.0.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Text updates that model; like a gate updates the data on a wire.}}{8}{section.0.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Text is made of sentences; like a circuit is made of gates and wires.}}{8}{section.0.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Let's say that \textbf  {\emph  {The meaning of a sentence is how it updates the meanings of its parts.}} As a first approximation, let's say that the \emph  {parts} of a sentence are the nouns it contains or refers to. Noun data is carried by wires. Collections of nouns are related by gates, which play the roles of verbs and adjectives.}}{8}{section.0.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Gates can be related by higher order gates, which play the roles of adverbs, adpositions, and conjunctions; anything that modifies the data of first order gates like verbs.}}{8}{section.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {0.1}What this thesis is about}{8}{section.0.1}\protected@file@percent }
\citation{vaswani_attention_2017}
\citation{openai_chatgpt_2022}
\citation{bastian_google_2022}
\citation{teddy_teddynpc_i_2022}
\citation{thompson_gpt-35_2022}
\citation{mcshane_linguistics_2021}
\citation{church_pendulum_2011}
\citation{hendrycks_measuring_2021}
\citation{}
\citation{}
\citation{floridi_fourth_2014}
\citation{sutton_bitter_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces In practice, higher order gates may be implemented as gates that modify parameters of other gates. Parameters are depicted as additional inputs to gates.}}{9}{section.0.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Grammar, and \emph  {function words} -- words that operate on meanings -- are absorbed by the geometry of the diagram.}}{9}{section.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {0.2}\textbf  {Question:} What is the practical value of studying language when Large Language Models exist?}{9}{section.0.2}\protected@file@percent }
\citation{chomsky_new_2000}
\citation{mollica_humans_2019}
\citation{herculano-houzel_remarkable_2012}
\citation{chowdhery_palm_2022,narang_pathways_2022}
\citation{khan_what_2023}
\citation{tom_goldstein_tomgoldsteincs_training_2022}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{deleted_user_stack_2018}
\citation{}
\citation{}
\citation{anderson_end_2008}
\citation{pietsch_epistemology_2022,desai_epistemological_2022}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{bender_climbing_2020}
\citation{searle_minds_1980}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\newpmemlabel{^_1}{12}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces  A caricature \citep  {deleted_user_stack_2018} that summarises the opposing epistemic stances of the symbolic/connectionist divide at a glance. For those unfamiliar, here is a recap. The symbolic side is synonymous with Good-old-fashioned-artificial-intelligence (GOFAI), research programme from the 70s to create general artificial intelligence. However, programming this explicitly turned out to be very hard because it was tantamount to systematising all of reasoning and knowledge \citep  {}frameproblem, which is why GOFAI is sometimes described as knowledge-based. In the meantime connectionist methods -- today synonymous with Deep Learning \citep  {} -- leapfrogged GOFAI, for reasons explored in more detail in Section \ref  {}. What distinguished connectionism was a reliance on data and compute rather than explicit programming, so it is sometimes described as knowledge-lean. A bullish sentiment arose among connectionists that cranking the handle to increase the size of the computer and the amount of training data would suffice to eventually obtain general artificial intelligence \citep  {anderson_end_2008}. Debates surrounding this position fall generally under the umbrella of the epistemology of Data Science \citep  {pietsch_epistemology_2022,desai_epistemological_2022}. In the case of LLMs specifically, modern debates of the bullish sentiment are developing, often rapidly. For example, in a thorough survey of LLM capabilities, \citep  {} warned against a fallacious conflation of linguistic and cognitive abilities, while observing several failure modes of GPT3 in cognitive domains. By the time the paper was published, those observations no longer held for GPT3's successor, ChatGPT \citep  {}, which patched the failures with the introduction of reinforcement learning. }}{13}{Item.3}\protected@file@percent }
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\@writefile{toc}{\contentsline {section}{\numberline {0.3}\textbf  {Question:} How do string diagrams help us understand language better?}{15}{section.0.3}\protected@file@percent }
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\bibstyle{plain}
\bibdata{thesis_intro}
\bibcite{anderson_end_2008}{{1}{}{{}}{{}}}
\bibcite{bastian_google_2022}{{2}{}{{}}{{}}}
\bibcite{bender_climbing_2020}{{3}{}{{}}{{}}}
\bibcite{chomsky_new_2000}{{4}{}{{}}{{}}}
\bibcite{chowdhery_palm_2022}{{5}{}{{}}{{}}}
\bibcite{church_pendulum_2011}{{6}{}{{}}{{}}}
\bibcite{deleted_user_stack_2018}{{7}{}{{}}{{}}}
\bibcite{desai_epistemological_2022}{{8}{}{{}}{{}}}
\bibcite{floridi_fourth_2014}{{9}{}{{}}{{}}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Bibliography}{19}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{hendrycks_measuring_2021}{{10}{}{{}}{{}}}
\bibcite{herculano-houzel_remarkable_2012}{{11}{}{{}}{{}}}
\bibcite{joyal_geometry_1991}{{12}{}{{}}{{}}}
\bibcite{khan_what_2023}{{13}{}{{}}{{}}}
\bibcite{lane_categories_2010}{{14}{}{{}}{{}}}
\bibcite{maclane_natural_1963}{{15}{}{{}}{{}}}
\bibcite{mcshane_linguistics_2021}{{16}{}{{}}{{}}}
\bibcite{mollica_humans_2019}{{17}{}{{}}{{}}}
\bibcite{narang_pathways_2022}{{18}{}{{}}{{}}}
\bibcite{openai_chatgpt_2022}{{19}{}{{}}{{}}}
\bibcite{pietsch_epistemology_2022}{{20}{}{{}}{{}}}
\bibcite{searle_minds_1980}{{21}{}{{}}{{}}}
\bibcite{selinger_survey_2010}{{22}{}{{}}{{}}}
\bibcite{sutton_bitter_2019}{{23}{}{{}}{{}}}
\bibcite{teddy_teddynpc_i_2022}{{24}{}{{}}{{}}}
\bibcite{thompson_gpt-35_2022}{{25}{}{{}}{{}}}
\bibcite{tom_goldstein_tomgoldsteincs_training_2022}{{26}{}{{}}{{}}}
\bibcite{vaswani_attention_2017}{{27}{}{{}}{{}}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{23}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:stringdiagrams}{{2}{23}{Background}{chapter.2}{}}
\citation{}
\citation{}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Process Theories}{24}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}What does it mean to copy and delete?}{27}{subsection.2.1.1}\protected@file@percent }
\newlabel{relcopy}{{2.1.6}{27}{Sets and relations}{theorem.2.1.6}{}}
\newlabel{cocom}{{2.1}{28}{What does it mean to copy and delete?}{equation.2.1.1}{}}
\newlabel{ex:copyablestate}{{2.1.7}{28}{Not all states are copyable}{theorem.2.1.7}{}}
\newlabel{ft:determinism}{{2.1.8}{28}{}{theorem.2.1.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}What is an update?}{28}{subsection.2.1.2}\protected@file@percent }
\newlabel{ss:update}{{2.1.2}{28}{What is an update?}{subsection.2.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Spatial predicates}{29}{subsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Deterministic Neural Nets and Closed Monoidal Categories}{30}{subsection.2.1.4}\protected@file@percent }
\citation{}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.5}Pregroup diagrams and correlations}{33}{subsection.2.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.6}Equational Constraints and Frobenius Algebras}{33}{subsection.2.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.7}Processes, Sets, and Computers}{33}{subsection.2.1.7}\protected@file@percent }
\citation{}
\newlabel{sec:proctheory}{{2.1.7}{34}{Processes, Sets, and Computers}{subsection.2.1.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Semantics and Syntax of String Diagrams}{35}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Symmetric Monoidal Categories}{35}{subsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}PROPs}{35}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}1-object 4-categories}{35}{subsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}An introduction to weak n-categories for formal linguists}{36}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}String-rewrite systems as 1-object-2-categories}{36}{subsection.2.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The category in question can be visualised as a commutative diagram.}}{37}{subsection.2.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces When there are too many generating morphisms, we can instead present the same data as a table of $n$-cells; there is a single 0-cell $\star $, and three non-identity 1-cells corresponding to $\leavevmode {\color  {green}\alpha }, \leavevmode {\color  {orange}\beta }, \leavevmode {\color  {cyan}\gamma }$, each with source and target 0-cells $\star $. Typically identity morphisms can be omitted from tables as they come for free. Observe that composition of identities enforces the behaviour of the empty string, so that for any string $x$, we have $\epsilon \cdot x = x = \epsilon \cdot x$.}}{37}{subsection.2.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces For a concrete example, we can depict the string $\leavevmode {\color  {green}\alpha } \cdot \leavevmode {\color  {cyan}\gamma } \cdot \leavevmode {\color  {cyan}\gamma } \cdot \leavevmode {\color  {orange}\beta }$ as a morphism in a commuting diagram.}}{37}{subsection.2.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces The string-diagrammatic view, where $\star $ is treated as a wire and morphisms are treated as boxes or dots is an expression of the same data under the Poincar\'{e} dual.}}{38}{subsection.2.3.1}\protected@file@percent }
\newlabel{fig:ruleR}{{2.3.1}{38}{String-rewrite systems as 1-object-2-categories}{subsection.2.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces We can visualise the rule as a commutative diagram where $\leavevmode {\color  {magenta}R}$ is a 2-cell between the source and target 1-cells. Just as 1-cells are arrows between 0-cell points in a commuting diagram, a 2-cell can also be conceptualised as a directed surface from a 1-cell to another. Taking the Poincar\'{e} dual of this view gives us a string diagram for the 2-cell $\leavevmode {\color  {magenta}R}$.}}{38}{subsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}A context free grammar to generate \texttt  {Alice sees Bob quickly run to school}}{38}{subsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Tree Adjoining Grammars}{41}{subsection.2.3.3}\protected@file@percent }
\newlabel{prop:cfgastag1}{{2.3.4}{44}{Leaf-ansatzes of CFGs are precisely TAGs with only initial trees and substitution}{theorem.2.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Tree adjoining grammars with local constraints}{48}{subsection.2.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Braiding, symmetries, and suspension}{50}{subsection.2.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.6}TAGs with links}{54}{subsection.2.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}String Diagrams for Text}{61}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:textcircuits}{{3}{61}{String Diagrams for Text}{chapter.3}{}}
\citation{}
\citation{}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Previously, on DisCoCat}{62}{section.3.1}\protected@file@percent }
\citation{}
\citation{}
\citation{}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}How do we communicate using language?}{66}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Grammars of speakers and listeners}{67}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Discrete Monoidal Fibrations}{74}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Relating the generative grammar to a pregroup grammar via a discrete monoidal fibration}{79}{subsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Discrete monoidal fibrations for grammatical functions}{85}{subsection.3.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}Discussion}{85}{subsection.3.2.5}\protected@file@percent }
\citation{hopcroft_introduction_1979}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces We will depict derivations of strings as planar "trees". The diagrams are read from top to bottom.}}{87}{section.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces These "trees" may have multiple edges from a parent node to a child node. We drop symbolic labels for intermediate symbols, and replace them by coloured edges. For example, \texttt  {NP} becomes a black edge and \texttt  {IVP} becomes a green edge. As we introduce the rules, we will also keep to a coloring convention for typed wires, such that later on we may omit typings such as \texttt  {IVP} from diagrams without confusion.}}{87}{section.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces We now introduce a phrase structure grammar by giving the tree-fragments for the grammatical types, initially for what we call \emph  {simple} sentences, which have a single verb that does not take a sentential complement. A simple sentence may contain a single \textbf  {intransitive} or \textbf  {transitive} verb. In the former case, the sentence consists of a noun-phrase followed by a intransitive-verb-phrase (e.g. \texttt  {\underline  {ALICE RUNS.}}). $\texttt  {S} \mapsto \texttt  {NP} \cdot \texttt  {IVP}$}}{87}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}A hybrid grammar for text}{87}{section.3.3}\protected@file@percent }
\newlabel{sec:grammar}{{3.3}{87}{A hybrid grammar for text}{section.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces In the latter case, a sentence consists of a noun-phrase, transitive-verb-phrase, and another noun-phrase (e.g.\nobreakspace  {}\texttt  {\underline  {ALICE LIKES BOB.}}). $\texttt  {S} \mapsto \texttt  {NP}_1 \cdot \texttt  {TVP} \cdot \texttt  {NP}_2$}}{88}{section.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces There also are the terminal rules for verbs, where the terminal symbols of the grammar are verbs of the appropriate type e.g.\nobreakspace  {}intransitive: $\texttt  {IVP} \mapsto \texttt  {\underline  {IV}}$}}{88}{section.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Or transitive: $\texttt  {TVP} \mapsto \texttt  {\underline  {TV}}$. Going forward, we omit the terminal rules in favour of giving examples of finished derivations, from which terminals can be inferred.}}{88}{section.3.3}\protected@file@percent }
\newlabel{rule1}{{3.8}{88}{A hybrid grammar for text}{equation.3.3.8}{}}
\newlabel{rule2}{{3.9}{88}{A hybrid grammar for text}{equation.3.3.9}{}}
\newlabel{rule3}{{3.10}{88}{A hybrid grammar for text}{equation.3.3.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces \textbf  {Adjectives} can appear before a noun-phrase (e.g.\nobreakspace  {}\texttt  {\underline  {DRUNK HAPPY BOB.}}) $\texttt  {NP} \mapsto \texttt  {ADJ} \cdot \texttt  {NP}$.}}{89}{equation.3.3.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Or, using the copular \texttt  {\underline  {IS}} considered as a verb, a single adjective can appear after a noun-phrase (e.g.\nobreakspace  {}\texttt  {\underline  {BOB IS DRUNK.}}) $\texttt  {S} \mapsto \texttt  {NP} \cdot \texttt  {\underline  {IS}} \cdot \texttt  {ADJ}$}}{89}{equation.3.3.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces \textbf  {Adverbs} can appear before a verb (e.g. \texttt  {\underline  {ALICE QUICKLY HAPPILY RUNS.}}) $\texttt  {IVP} \mapsto \texttt  {ADV} \cdot \texttt  {IVP}$}}{89}{equation.3.3.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces $\texttt  {TVP} \mapsto \texttt  {ADV} \cdot \texttt  {TVP}$}}{89}{equation.3.3.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces \textbf  {Adpositions} can appear to the right of an intransitive-verb-phrase, followed by a noun-phrase (e.g.\nobreakspace  {}from \texttt  {\underline  {ALICE RUNS.}} to \texttt  {\underline  {ALICE RUNS TOWARDS BOB.}}). $\texttt  {IVP} \mapsto \texttt  {IVP} \cdot \texttt  {ADP} \cdot \texttt  {NP}$.}}{90}{equation.3.3.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces In the presence of a transitive-verb-phrase flanked by a noun-phrase to the right, we may add to the right an adposition followed by a noun-phrase (e.g.\nobreakspace  {}from \texttt  {\underline  {ALICE THROWS BEER.}} to \texttt  {\underline  {ALICE THROWS BEER TOWARDS BOB.}}) $\texttt  {TVP} \cdot \texttt  {NP}_1 \mapsto \texttt  {TVP} \cdot \texttt  {NP}_1 \cdot \texttt  {ADP} \cdot \texttt  {NP}_2$}}{90}{equation.3.3.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces \textbf  {Subject relative pronouns} replace the subject noun of a parse tree $\texttt  {S}_2$, and points to a noun in another, previous parse tree $\texttt  {S}_1$, usually the object noun.}}{90}{theorem.3.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces In English there is another special use of the subject relative pronoun to coordinate a single noun across two subsequent phrases. Given parse trees corresponding to sentences $\texttt  {S}_1$ and $\texttt  {S}_2$ in that order, this special case arises when the subject noun of $\texttt  {S}_2$ points towards a subject noun in $\texttt  {S}_1$. The result of the tree-transformation is that we have, in order: the noun-phrase (along with any adjectives) of $\texttt  {S}_1$, followed by $\texttt  {S}_1$ with the later noun replaced by the relative pronoun, followed by $\texttt  {S}_2$ with its pointing noun removed. We use a multiarrow to point out more than two pronominally identified nouns.}}{91}{theorem.3.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces For \textbf  {object relative pronouns}, we take consecutive sentences $\texttt  {S}_1$ and $\texttt  {S}_2$. If the object noun of $\texttt  {S}_2$ points to the object noun of $\texttt  {S}_1$, the object relative pronoun comes after the first occurrence, and the second occurrence of the noun is replaced by a blank.}}{91}{theorem.3.3.4}\protected@file@percent }
\newlabel{sec:phrscope}{{3.3}{91}{A hybrid grammar for text}{theorem.3.3.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.16}{\ignorespaces \textbf  {Verbs with Sentential Complement} require phrase scope. We treat verbs with a sentential complement -- such as to \texttt  {\underline  {SEE}} or \texttt  {\underline  {THINK}} -- as their own grammatical class of verb.$\texttt  {S} \mapsto \texttt  {NP} \cdot \texttt  {SCV} \cdot \texttt  {S}$}}{92}{theorem.3.3.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.17}{\ignorespaces \textbf  {Conjunctions} we treat similarly to verbs with a sentential complement}}{92}{theorem.3.3.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.18}{\ignorespaces We re-express the rules for verbs with sentential complement and conjunctions to additionally express phrase boundaries. $\texttt  {S} \mapsto \texttt  {NP} \cdot \texttt  {SCV} \cdot \begin  {color}{blue}( \end  {color}\xspace  \ \cdot \ \texttt  {S} \ \cdot \ \begin  {color}{blue}) \end  {color}\xspace  $}}{93}{theorem.3.3.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.19}{\ignorespaces $\texttt  {S} \mapsto \begin  {color}{blue}( \end  {color}\xspace  \ \cdot \ \texttt  {S} \ \cdot \ \begin  {color}{blue}) \end  {color}\xspace  \cdot \texttt  {CNJ} \cdot \begin  {color}{blue}( \end  {color}\xspace  \ \cdot \ \texttt  {S} \ \cdot \ \begin  {color}{blue}) \end  {color}\xspace  $}}{93}{theorem.3.3.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.20}{\ignorespaces To model the permission of nouns to partially live outside the scope of a phrase as in the example above, we include the following rules that allow a \texttt  {NP} to `cross the border' of a phrase boundary. $\begin  {color}{blue}( \end  {color}\xspace  \ \cdot \ \texttt  {NP} \mapsto \texttt  {NP} \cdot \begin  {color}{blue}( \end  {color}\xspace  $}}{93}{theorem.3.3.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.21}{\ignorespaces $\texttt  {NP} \ \cdot \ \begin  {color}{blue}) \end  {color}\xspace  \mapsto \ \begin  {color}{blue}) \end  {color}\xspace  \ \cdot \texttt  {NP}$}}{93}{theorem.3.3.7}\protected@file@percent }
\newpmemlabel{^_2}{94}
\@writefile{lof}{\contentsline {figure}{\numberline {3.22}{\ignorespaces Generating text with hybrid grammar, illustrated}}{95}{theorem.3.3.8}\protected@file@percent }
\newlabel{fig:comic1}{{3.22}{95}{A hybrid grammar for text}{theorem.3.3.8}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Continuous relations: a palette for toy models}{97}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:contrel}{{4}{97}{Continuous relations: a palette for toy models}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Continuous Relations: A concept-compliant setting for text circuits}{98}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Why not use something already out there?}{99}{subsection.4.1.1}\protected@file@percent }
\newlabel{just:rel}{{4.1.1}{99}{Why not use something already out there?}{subsection.4.1.1}{}}
\newpmemlabel{^_3}{100}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Continuous Relations}{102}{section.4.2}\protected@file@percent }
\newlabel{defn:Contrelation}{{4.2.4}{102}{Continuous Relation}{theorem.4.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}\textbf  {ContRel} diagrammatically}{103}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Relations that are always continuous}{103}{subsection.4.3.1}\protected@file@percent }
\newlabel{ex:nontop}{{4.4.1}{107}{A noncontinuous relation}{theorem.4.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Continuous Relations by examples}{107}{section.4.4}\protected@file@percent }
\newlabel{prop:states}{{4.4.3}{108}{}{theorem.4.4.3}{}}
\newlabel{prop:tests}{{4.4.4}{108}{}{theorem.4.4.4}{}}
\newlabel{prop:emptyrel}{{4.4.6}{108}{}{theorem.4.4.6}{}}
\newlabel{prop:fullrel}{{4.4.8}{108}{}{theorem.4.4.8}{}}
\newlabel{prop:bowtie}{{4.4.9}{108}{}{theorem.4.4.9}{}}
\newlabel{prop:func}{{4.4.10}{108}{}{theorem.4.4.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Regions of $\blacksquare $ in the image of the yellow point alone will be coloured yellow, and regions in the image of both yellow and cyan will be coloured green:}}{109}{theorem.4.4.18}\protected@file@percent }
\newlabel{fig:yellowgreen}{{4.1}{109}{Continuous Relations}{theorem.4.4.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Regions in the image of the cyan point alone cannot be open sets by continuity, so they are either points or lines. Points and lines in cyan must be surrounded by an open region in either yellow or green, or else we violate continuity (open sets in red).}}{109}{theorem.4.4.19}\protected@file@percent }
\newlabel{fig:cyan}{{4.2}{109}{Continuous Relations}{theorem.4.4.19}{}}
\newlabel{prop:idrel}{{4.4.12}{109}{}{theorem.4.4.12}{}}
\newlabel{prop:framehom}{{4.4.14}{109}{}{theorem.4.4.14}{}}
\newlabel{cor:homspace}{{4.4.15}{109}{}{theorem.4.4.15}{}}
\newlabel{lem:capideal}{{4.4.18}{109}{Partial functions are a $\cap $-ideal}{theorem.4.4.18}{}}
\newlabel{lem:edgecomplete}{{4.4.19}{109}{Any single edge can be extended to a continuous partial function}{theorem.4.4.19}{}}
\newlabel{prop:hombasis}{{4.4.20}{109}{}{theorem.4.4.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces A continuous relation $\mathcal  {S} \rightarrow \blacksquare $: "Flower and critter in a sunny field".}}{110}{theorem.4.4.19}\protected@file@percent }
\newlabel{fig:flower}{{4.3}{110}{Continuous Relations}{theorem.4.4.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces A continuous relation $\blacksquare \rightarrow \mathcal  {S}$: "still math?". Black lines and dots indicate gaps.}}{110}{theorem.4.4.19}\protected@file@percent }
\newlabel{fig:shitpost}{{4.4}{110}{Continuous Relations}{theorem.4.4.19}{}}
\newpmemlabel{^_4}{110}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Hasse diagram of all continuous relations from the Sierpi\'{n}ski space to itself. Each relation is depicted left to right, and inclusion order is bottom-to-top. Relations that form the topological basis are boxed.}}{111}{theorem.4.4.20}\protected@file@percent }
\newlabel{fig:hassesierpinski}{{4.5}{111}{Continuous Relations}{theorem.4.4.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces  continuous functions $[0,1] \rightarrow \blacksquare $ follow the na\"{i}ve notion of continuity: a line one can draw on paper without lifting the pen off the page. }}{112}{theorem.4.4.20}\protected@file@percent }
\newlabel{fig:contline}{{4.6}{112}{Continuous Relations}{theorem.4.4.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces  So a continuous partial function is \texttt  {"(countably) many (open-ended) lines, each of which one can draw on paper without lifting the pen off the page."} }}{112}{theorem.4.4.20}\protected@file@percent }
\newlabel{fig:contline}{{4.7}{112}{Continuous Relations}{theorem.4.4.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces We can control the thickness of the brushstroke, by taking the union of (uncountably) many lines.}}{112}{theorem.4.4.20}\protected@file@percent }
\newlabel{fig:thickbrush}{{4.8}{112}{Continuous Relations}{theorem.4.4.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Assign the visible spectrum of light to $[0,1]$. Colour open sets according to perceptual addition of light, computing brightness by normalising the measure of the open set.}}{112}{theorem.4.4.20}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Like it or not, a continuous relation $[0,1] \rightarrow \blacksquare $: "The Starry Night", by Vincent van Gogh.}}{113}{theorem.4.4.20}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Populating space with shapes using sticky spiders}{113}{section.4.5}\protected@file@percent }
\newlabel{sec:stickyspider}{{4.5}{113}{Populating space with shapes using sticky spiders}{section.4.5}{}}
\newpmemlabel{^_5}{113}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}When does an object have a spider (or something close to one)?}{113}{subsection.4.5.1}\protected@file@percent }
\newlabel{ex:compnotspider}{{4.5.2}{113}{The copy-compare spiders of $\mathbf {Rel}$ are not always continuous}{theorem.4.5.2}{}}
\newlabel{prop:copydiscrete}{{4.5.3}{113}{}{theorem.4.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces The generators (in dashed boxes) and relations that make a spider. When the spider satisfies in addition the three inequalities b1-3, we call it a \textbf  {relation-spider}.}}{114}{section.4.5}\protected@file@percent }
\newlabel{fig:spiderbicate}{{4.11}{114}{Populating space with shapes using sticky spiders}{section.4.5}{}}
\newlabel{defn:stickyspider}{{4.5.5}{115}{Sticky spiders}{theorem.4.5.5}{}}
\newlabel{prop:splitmeanssticky}{{4.5.7}{117}{Every idempotent that splits through a discrete topology gives a sticky spider}{theorem.4.5.7}{}}
\newlabel{thm:stickygraphical}{{4.5.8}{119}{}{theorem.4.5.8}{}}
\newlabel{prop:counitdelete}{{4.5.9}{121}{comult/copy implies counit/delete}{theorem.4.5.9}{}}
\newlabel{lem:allornothing}{{4.5.10}{122}{All-or-Nothing}{theorem.4.5.10}{}}
\newlabel{prop:epointcopy}{{4.5.11}{124}{$e$ of any point is $e$-copiable}{theorem.4.5.11}{}}
\newlabel{prop:copiablebasis}{{4.5.12}{125}{The unit is the union of all $e$-copiables}{theorem.4.5.12}{}}
\newlabel{prop:decompidem}{{4.5.13}{126}{$e$-copiable decomposition of $e$}{theorem.4.5.13}{}}
\newlabel{prop:decompcounit}{{4.5.14}{127}{$e$-copiable decomposition of counit}{theorem.4.5.14}{}}
\newlabel{lem:match}{{4.5.15}{128}{$e$-copiables are orthogonal under multiplication}{theorem.4.5.15}{}}
\newlabel{lem:comatch}{{4.5.17}{130}{Co-match}{theorem.4.5.17}{}}
\newlabel{lem:ecopyfixpoint}{{4.5.18}{131}{e-copiables are e-fixpoints}{theorem.4.5.18}{}}
\newlabel{lem:ecopynormal}{{4.5.19}{132}{$e$-copiables are normal}{theorem.4.5.19}{}}
\newlabel{prop:decompmult}{{4.5.20}{133}{$e$-copiable decomposition of multiplication}{theorem.4.5.20}{}}
\newlabel{prop:decompcomult}{{4.5.21}{134}{$e$-copiable decomposition of comultiplication}{theorem.4.5.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Mathematician's endnotes}{137}{section.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}The category \textbf  {ContRel}}{137}{subsection.4.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Symmetric Monoidal structure}{137}{subsection.4.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}Rig category structure}{138}{subsection.4.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.4}\textbf  {ContRel} and \textbf  {Rel} are related by a free-forgetful adjunction}{139}{subsection.4.6.4}\protected@file@percent }
\newlabel{lem:disccont}{{4.6.7}{139}{Any relation $R$ between discrete topologies is continuous}{theorem.4.6.7}{}}
\newlabel{lem:idadj}{{4.6.10}{139}{$RL = 1_{\textbf {Rel}}$}{theorem.4.6.10}{}}
\newlabel{lem:coarse}{{4.6.12}{139}{Coarsening is a continuous relation}{theorem.4.6.12}{}}
\newlabel{prop:reladj}{{4.6.13}{140}{$L \dashv R$}{theorem.4.6.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.5}Why not Span(\textbf  {Top})?}{141}{subsection.4.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.6}Why not a Kleisli construction on \textbf  {Top}?}{141}{subsection.4.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.7}Where is the topology coming from?}{142}{subsection.4.6.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.8}Why are continuous relations worth the trouble?}{142}{subsection.4.6.8}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Sketches of the shape of language}{145}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:sketches}{{5}{145}{Sketches of the shape of language}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Topological concepts in flatland via \textbf  {ContRel}}{146}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Shapes and places}{146}{subsection.5.1.1}\protected@file@percent }
\newlabel{sec:shapes}{{5.1.1}{146}{Shapes and places}{subsection.5.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}The unit interval}{149}{subsection.5.1.2}\protected@file@percent }
\newlabel{sec:interval}{{5.1.2}{149}{The unit interval}{subsection.5.1.2}{}}
\newlabel{thm:Friedman}{{5.1.7}{149}{Friedman}{theorem.5.1.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Displacing shapes}{152}{subsection.5.1.3}\protected@file@percent }
\newlabel{sec:displace}{{5.1.3}{152}{Displacing shapes}{subsection.5.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.4}Moving shapes}{155}{subsection.5.1.4}\protected@file@percent }
\newlabel{sec:moving}{{5.1.4}{155}{Moving shapes}{subsection.5.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.5}Rigid motion}{159}{subsection.5.1.5}\protected@file@percent }
\newlabel{sec:rigidmotion}{{5.1.5}{159}{Rigid motion}{subsection.5.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.6}Modelling linguistic topological concepts}{162}{subsection.5.1.6}\protected@file@percent }
\newlabel{sec:topconcept}{{5.1.6}{162}{Modelling linguistic topological concepts}{subsection.5.1.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.7}States, actions, manner}{167}{subsection.5.1.7}\protected@file@percent }
\newlabel{sec:statesactions}{{5.1.7}{167}{States, actions, manner}{subsection.5.1.7}{}}
\newlabel{cons:morph}{{5.1.11}{171}{Morphing sticky spiders with homotopies}{theorem.5.1.11}{}}
\newlabel{sec:topconcepts}{{5.1}{173}{Topological concepts in flatland via \textbf {ContRel}}{theorem.5.1.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}On entification, general anaphora, computers, and lassos.}{174}{section.5.2}\protected@file@percent }
\newlabel{sec:lassos}{{5.1}{185}{Topological concepts in flatland via \textbf {ContRel}}{theorem.5.2.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}(Im)possibility results for learning text circuits from data}{186}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Approximating Text Circuits with deterministic neural nets}{186}{subsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Text circuits with unbounded depth and width}{191}{subsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Text circuits of unbounded width in noncartesian settings}{192}{subsection.5.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}A value proposition for quantum machine learning}{193}{subsection.5.3.4}\protected@file@percent }
\newlabel{sec:learn}{{5.1}{194}{Topological concepts in flatland via \textbf {ContRel}}{subsection.5.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Towards learning gates that satisfy First-Order Logic specifications over boundedly finite models}{195}{section.5.4}\protected@file@percent }
\newlabel{prop:allthenex}{{5.4.3}{196}{}{theorem.5.4.3}{}}
\newlabel{prop:promotion}{{5.4.4}{197}{}{theorem.5.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Discussion}{199}{subsection.5.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Modelling metaphor}{200}{section.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Orders, Temperature, Colour, Mood}{200}{subsection.5.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Complex conceptual structure}{200}{subsection.5.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}}{201}{subsection.5.5.3}\protected@file@percent }
\citation{}
\citation{}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Grounding verbs of cognition}{202}{section.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.1}Capabilities of spatial agents}{202}{subsection.5.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.2}In which directions do the animals run?}{202}{subsection.5.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.3}How do the animals run in the directions they run?}{202}{subsection.5.6.3}\protected@file@percent }
\citation{}
\citation{}
\citation{}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.4}Why do the animals run the way they do?}{204}{subsection.5.6.4}\protected@file@percent }
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\ttl@finishall
\gdef \@abspage@last{205}
