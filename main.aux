\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {0}Synopsis}{7}{chapter.0}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{joyal_geometry_1991,joyal_geometry_nodate,maclane_natural_1963,lane_categories_2010,selinger_survey_2010}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Let's say that \textbf  \emph  {{the meaning of text is how it updates a model.}} So we start with some model of the way things are, modelled as data on a wire.}}{8}{section.0.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Text updates that model; like a gate updates the data on a wire.}}{8}{section.0.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Text is made of sentences; like a circuit is made of gates and wires.}}{8}{section.0.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Let's say that \textbf  {\emph  {The meaning of a sentence is how it updates the meanings of its parts.}} As a first approximation, let's say that the \emph  {parts} of a sentence are the nouns it contains or refers to. Noun data is carried by wires. Collections of nouns are related by gates, which play the roles of verbs and adjectives.}}{8}{section.0.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Gates can be related by higher order gates, which play the roles of adverbs, adpositions, and conjunctions; anything that modifies the data of first order gates like verbs.}}{8}{section.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {0.1}What this thesis is about}{8}{section.0.1}\protected@file@percent }
\citation{vaswani_attention_2017}
\citation{openai_chatgpt_2022}
\citation{bastian_google_2022}
\citation{teddy_teddynpc_i_2022}
\citation{thompson_gpt-35_2022}
\citation{mcshane_linguistics_2021}
\citation{church_pendulum_2011}
\citation{hendrycks_measuring_2021}
\citation{}
\citation{}
\citation{floridi_fourth_2014}
\citation{sutton_bitter_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces In practice, higher order gates may be implemented as gates that modify parameters of other gates. Parameters are depicted as additional inputs to gates.}}{9}{section.0.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Grammar, and \emph  {function words} -- words that operate on meanings -- are absorbed by the geometry of the diagram.}}{9}{section.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {0.2}\textbf  {Question:} What is the practical value of studying language when Large Language Models exist?}{9}{section.0.2}\protected@file@percent }
\citation{chomsky_new_2000}
\citation{mollica_humans_2019}
\citation{herculano-houzel_remarkable_2012}
\citation{chowdhery_palm_2022,narang_pathways_2022}
\citation{khan_what_2023}
\citation{tom_goldstein_tomgoldsteincs_training_2022}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{deleted_user_stack_2018}
\citation{}
\citation{}
\citation{anderson_end_2008}
\citation{pietsch_epistemology_2022,desai_epistemological_2022}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{bender_climbing_2020}
\citation{searle_minds_1980}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\newpmemlabel{^_1}{12}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces  A caricature \citep  {deleted_user_stack_2018} that summarises the opposing epistemic stances of the symbolic/connectionist divide at a glance. For those unfamiliar, here is a recap. The symbolic side is synonymous with Good-old-fashioned-artificial-intelligence (GOFAI), research programme from the 70s to create general artificial intelligence. However, programming this explicitly turned out to be very hard because it was tantamount to systematising all of reasoning and knowledge \citep  {}frameproblem, which is why GOFAI is sometimes described as knowledge-based. In the meantime connectionist methods -- today synonymous with Deep Learning \citep  {} -- leapfrogged GOFAI, for reasons explored in more detail in Section \ref  {}. What distinguished connectionism was a reliance on data and compute rather than explicit programming, so it is sometimes described as knowledge-lean. A bullish sentiment arose among connectionists that cranking the handle to increase the size of the computer and the amount of training data would suffice to eventually obtain general artificial intelligence \citep  {anderson_end_2008}. Debates surrounding this position fall generally under the umbrella of the epistemology of Data Science \citep  {pietsch_epistemology_2022,desai_epistemological_2022}. In the case of LLMs specifically, modern debates of the bullish sentiment are developing, often rapidly. For example, in a thorough survey of LLM capabilities, \citep  {} warned against a fallacious conflation of linguistic and cognitive abilities, while observing several failure modes of GPT3 in cognitive domains. By the time the paper was published, those observations no longer held for GPT3's successor, ChatGPT \citep  {}, which patched the failures with the introduction of reinforcement learning. }}{13}{Item.3}\protected@file@percent }
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\@writefile{toc}{\contentsline {section}{\numberline {0.3}\textbf  {Question:} How do string diagrams help us understand language better?}{15}{section.0.3}\protected@file@percent }
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\citation{}
\@writefile{toc}{\contentsline {section}{\numberline {0.4}Synopsis of the thesis}{18}{section.0.4}\protected@file@percent }
\bibstyle{plain}
\bibdata{thesis_intro}
\bibcite{anderson_end_2008}{{1}{}{{}}{{}}}
\bibcite{bastian_google_2022}{{2}{}{{}}{{}}}
\bibcite{bender_climbing_2020}{{3}{}{{}}{{}}}
\bibcite{chomsky_new_2000}{{4}{}{{}}{{}}}
\bibcite{chowdhery_palm_2022}{{5}{}{{}}{{}}}
\bibcite{church_pendulum_2011}{{6}{}{{}}{{}}}
\bibcite{deleted_user_stack_2018}{{7}{}{{}}{{}}}
\bibcite{desai_epistemological_2022}{{8}{}{{}}{{}}}
\bibcite{floridi_fourth_2014}{{9}{}{{}}{{}}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Bibliography}{21}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{hendrycks_measuring_2021}{{10}{}{{}}{{}}}
\bibcite{herculano-houzel_remarkable_2012}{{11}{}{{}}{{}}}
\bibcite{joyal_geometry_1991}{{12}{}{{}}{{}}}
\bibcite{khan_what_2023}{{13}{}{{}}{{}}}
\bibcite{lane_categories_2010}{{14}{}{{}}{{}}}
\bibcite{maclane_natural_1963}{{15}{}{{}}{{}}}
\bibcite{mcshane_linguistics_2021}{{16}{}{{}}{{}}}
\bibcite{mollica_humans_2019}{{17}{}{{}}{{}}}
\bibcite{narang_pathways_2022}{{18}{}{{}}{{}}}
\bibcite{openai_chatgpt_2022}{{19}{}{{}}{{}}}
\bibcite{pietsch_epistemology_2022}{{20}{}{{}}{{}}}
\bibcite{searle_minds_1980}{{21}{}{{}}{{}}}
\bibcite{selinger_survey_2010}{{22}{}{{}}{{}}}
\bibcite{sutton_bitter_2019}{{23}{}{{}}{{}}}
\bibcite{teddy_teddynpc_i_2022}{{24}{}{{}}{{}}}
\bibcite{thompson_gpt-35_2022}{{25}{}{{}}{{}}}
\bibcite{tom_goldstein_tomgoldsteincs_training_2022}{{26}{}{{}}{{}}}
\bibcite{vaswani_attention_2017}{{27}{}{{}}{{}}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{25}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:stringdiagrams}{{2}{25}{Background}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}A Partial History of String Diagrams}{26}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Formal visual representation}{27}{subsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Convergent Evolution}{27}{subsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Formal visual reasoning}{27}{subsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Process Theories}{28}{section.2.2}\protected@file@percent }
\newlabel{cocom}{{2.1}{31}{What does it mean to copy and delete?}{equation.2.2.1}{}}
\newlabel{ex:copyablestate}{{2.2.7}{31}{Not all states are copyable}{theorem.2.2.7}{}}
\newlabel{ft:determinism}{{2.2.8}{31}{}{theorem.2.2.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}What does it mean to copy and delete?}{31}{subsection.2.2.1}\protected@file@percent }
\newlabel{relcopy}{{2.2.6}{31}{Sets and relations}{theorem.2.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}What is an update?}{32}{subsection.2.2.2}\protected@file@percent }
\newlabel{ss:update}{{2.2.2}{32}{What is an update?}{subsection.2.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Spatial predicates}{33}{subsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Some basic properties of linguistic spatial relations}{34}{subsection.2.2.4}\protected@file@percent }
\newlabel{sec:proctheory}{{2.2.4}{34}{Some basic properties of linguistic spatial relations}{subsection.2.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Defining String Diagrams}{35}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Symmetric Monoidal Categories}{35}{subsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}PROPs}{35}{subsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}1-object 4-categories}{35}{subsection.2.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}A brief diagrammatic introduction to Neural Nets}{36}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}A brief history of formal linguistics from the categorial perspective}{39}{section.2.5}\protected@file@percent }
\newlabel{sec:linghist}{{2.5}{39}{A brief history of formal linguistics from the categorial perspective}{section.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Curry-Howard-Lambek}{39}{subsection.2.5.1}\protected@file@percent }
\newpmemlabel{^_2}{39}
\newpmemlabel{^_3}{39}
\newpmemlabel{^_4}{39}
\citation{montague1970universal}
\citation{montague1973proper}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}What did Montague consider grammar to be?}{40}{subsection.2.5.2}\protected@file@percent }
\newlabel{sec:monty}{{2.5.2}{40}{What did Montague consider grammar to be?}{subsection.2.5.2}{}}
\newlabel{algdata}{{2.5.1}{41}{Generating data of an Algebra}{theorem.2.5.1}{}}
\newlabel{ids}{{2.5.2}{41}{Identities}{theorem.2.5.2}{}}
\newlabel{constants}{{2.5.3}{41}{Constants}{theorem.2.5.3}{}}
\newlabel{comp}{{2.5.4}{41}{Composition}{theorem.2.5.4}{}}
\newlabel{polyop}{{2.5.5}{41}{Polynomial Operations}{theorem.2.5.5}{}}
\newlabel{homo}{{2.5.6}{41}{Homomorphism of Algebras}{theorem.2.5.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}On Syntax}{41}{subsection.2.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}String Diagrams for Text}{43}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:textcircuits}{{3}{43}{String Diagrams for Text}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}How do we communicate?}{44}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Speaking grammars, listening grammars}{44}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}A context free grammar to generate \texttt  {Alice sees Bob quickly run to school}}{47}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Relating the generative grammar to a pregroup grammar via a discrete monoidal fibration}{50}{subsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Discrete Monoidal Fibrations}{56}{subsection.3.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}Discrete monoidal fibrations for grammatical functions}{60}{subsection.3.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.6}Extended analysis: Tree Adjoining Grammars}{60}{subsection.3.1.6}\protected@file@percent }
\newlabel{prop:cfgastag1}{{3.1.13}{63}{Leaf-ansatzes of CFGs are precisely TAGs with only initial trees and substitution}{theorem.3.1.13}{}}
\citation{hopcroft_introduction_1979}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces We will depict derivations of strings as planar "trees". The diagrams are read from top to bottom.}}{68}{section.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces These "trees" may have multiple edges from a parent node to a child node. We drop symbolic labels for intermediate symbols, and replace them by coloured edges. For example, \texttt  {NP} becomes a black edge and \texttt  {IVP} becomes a green edge. As we introduce the rules, we will also keep to a coloring convention for typed wires, such that later on we may omit typings such as \texttt  {IVP} from diagrams without confusion.}}{68}{section.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces We now introduce a phrase structure grammar by giving the tree-fragments for the grammatical types, initially for what we call \emph  {simple} sentences, which have a single verb that does not take a sentential complement. A simple sentence may contain a single \textbf  {intransitive} or \textbf  {transitive} verb. In the former case, the sentence consists of a noun-phrase followed by a intransitive-verb-phrase (e.g. \texttt  {\underline  {ALICE RUNS.}}). $\texttt  {S} \mapsto \texttt  {NP} \cdot \texttt  {IVP}$}}{68}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}A hybrid grammar for text}{68}{section.3.2}\protected@file@percent }
\newlabel{sec:grammar}{{3.2}{68}{A hybrid grammar for text}{section.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces In the latter case, a sentence consists of a noun-phrase, transitive-verb-phrase, and another noun-phrase (e.g.\nobreakspace  {}\texttt  {\underline  {ALICE LIKES BOB.}}). $\texttt  {S} \mapsto \texttt  {NP}_1 \cdot \texttt  {TVP} \cdot \texttt  {NP}_2$}}{69}{section.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces There also are the terminal rules for verbs, where the terminal symbols of the grammar are verbs of the appropriate type e.g.\nobreakspace  {}intransitive: $\texttt  {IVP} \mapsto \texttt  {\underline  {IV}}$}}{69}{section.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Or transitive: $\texttt  {TVP} \mapsto \texttt  {\underline  {TV}}$. Going forward, we omit the terminal rules in favour of giving examples of finished derivations, from which terminals can be inferred.}}{69}{section.3.2}\protected@file@percent }
\newlabel{rule1}{{3.4}{69}{A hybrid grammar for text}{equation.3.2.4}{}}
\newlabel{rule2}{{3.5}{69}{A hybrid grammar for text}{equation.3.2.5}{}}
\newlabel{rule3}{{3.6}{69}{A hybrid grammar for text}{equation.3.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces \textbf  {Adjectives} can appear before a noun-phrase (e.g.\nobreakspace  {}\texttt  {\underline  {DRUNK HAPPY BOB.}}) $\texttt  {NP} \mapsto \texttt  {ADJ} \cdot \texttt  {NP}$.}}{70}{equation.3.2.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Or, using the copular \texttt  {\underline  {IS}} considered as a verb, a single adjective can appear after a noun-phrase (e.g.\nobreakspace  {}\texttt  {\underline  {BOB IS DRUNK.}}) $\texttt  {S} \mapsto \texttt  {NP} \cdot \texttt  {\underline  {IS}} \cdot \texttt  {ADJ}$}}{70}{equation.3.2.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces \textbf  {Adverbs} can appear before a verb (e.g. \texttt  {\underline  {ALICE QUICKLY HAPPILY RUNS.}}) $\texttt  {IVP} \mapsto \texttt  {ADV} \cdot \texttt  {IVP}$}}{70}{equation.3.2.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces $\texttt  {TVP} \mapsto \texttt  {ADV} \cdot \texttt  {TVP}$}}{70}{equation.3.2.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces \textbf  {Adpositions} can appear to the right of an intransitive-verb-phrase, followed by a noun-phrase (e.g.\nobreakspace  {}from \texttt  {\underline  {ALICE RUNS.}} to \texttt  {\underline  {ALICE RUNS TOWARDS BOB.}}). $\texttt  {IVP} \mapsto \texttt  {IVP} \cdot \texttt  {ADP} \cdot \texttt  {NP}$.}}{71}{equation.3.2.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces In the presence of a transitive-verb-phrase flanked by a noun-phrase to the right, we may add to the right an adposition followed by a noun-phrase (e.g.\nobreakspace  {}from \texttt  {\underline  {ALICE THROWS BEER.}} to \texttt  {\underline  {ALICE THROWS BEER TOWARDS BOB.}}) $\texttt  {TVP} \cdot \texttt  {NP}_1 \mapsto \texttt  {TVP} \cdot \texttt  {NP}_1 \cdot \texttt  {ADP} \cdot \texttt  {NP}_2$}}{71}{equation.3.2.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces \textbf  {Subject relative pronouns} replace the subject noun of a parse tree $\texttt  {S}_2$, and points to a noun in another, previous parse tree $\texttt  {S}_1$, usually the object noun.}}{71}{theorem.3.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces In English there is another special use of the subject relative pronoun to coordinate a single noun across two subsequent phrases. Given parse trees corresponding to sentences $\texttt  {S}_1$ and $\texttt  {S}_2$ in that order, this special case arises when the subject noun of $\texttt  {S}_2$ points towards a subject noun in $\texttt  {S}_1$. The result of the tree-transformation is that we have, in order: the noun-phrase (along with any adjectives) of $\texttt  {S}_1$, followed by $\texttt  {S}_1$ with the later noun replaced by the relative pronoun, followed by $\texttt  {S}_2$ with its pointing noun removed. We use a multiarrow to point out more than two pronominally identified nouns.}}{72}{theorem.3.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces For \textbf  {object relative pronouns}, we take consecutive sentences $\texttt  {S}_1$ and $\texttt  {S}_2$. If the object noun of $\texttt  {S}_2$ points to the object noun of $\texttt  {S}_1$, the object relative pronoun comes after the first occurrence, and the second occurrence of the noun is replaced by a blank.}}{72}{theorem.3.2.4}\protected@file@percent }
\newlabel{sec:phrscope}{{3.2}{72}{A hybrid grammar for text}{theorem.3.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.16}{\ignorespaces \textbf  {Verbs with Sentential Complement} require phrase scope. We treat verbs with a sentential complement -- such as to \texttt  {\underline  {SEE}} or \texttt  {\underline  {THINK}} -- as their own grammatical class of verb.$\texttt  {S} \mapsto \texttt  {NP} \cdot \texttt  {SCV} \cdot \texttt  {S}$}}{73}{theorem.3.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.17}{\ignorespaces \textbf  {Conjunctions} we treat similarly to verbs with a sentential complement}}{73}{theorem.3.2.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.18}{\ignorespaces We re-express the rules for verbs with sentential complement and conjunctions to additionally express phrase boundaries. $\texttt  {S} \mapsto \texttt  {NP} \cdot \texttt  {SCV} \cdot \begin  {color}{blue}( \end  {color}\xspace  \ \cdot \ \texttt  {S} \ \cdot \ \begin  {color}{blue}) \end  {color}\xspace  $}}{74}{theorem.3.2.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.19}{\ignorespaces $\texttt  {S} \mapsto \begin  {color}{blue}( \end  {color}\xspace  \ \cdot \ \texttt  {S} \ \cdot \ \begin  {color}{blue}) \end  {color}\xspace  \cdot \texttt  {CNJ} \cdot \begin  {color}{blue}( \end  {color}\xspace  \ \cdot \ \texttt  {S} \ \cdot \ \begin  {color}{blue}) \end  {color}\xspace  $}}{74}{theorem.3.2.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.20}{\ignorespaces To model the permission of nouns to partially live outside the scope of a phrase as in the example above, we include the following rules that allow a \texttt  {NP} to `cross the border' of a phrase boundary. $\begin  {color}{blue}( \end  {color}\xspace  \ \cdot \ \texttt  {NP} \mapsto \texttt  {NP} \cdot \begin  {color}{blue}( \end  {color}\xspace  $}}{74}{theorem.3.2.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.21}{\ignorespaces $\texttt  {NP} \ \cdot \ \begin  {color}{blue}) \end  {color}\xspace  \mapsto \ \begin  {color}{blue}) \end  {color}\xspace  \ \cdot \texttt  {NP}$}}{74}{theorem.3.2.7}\protected@file@percent }
\newpmemlabel{^_5}{75}
\@writefile{lof}{\contentsline {figure}{\numberline {3.22}{\ignorespaces Generating text with hybrid grammar, illustrated}}{76}{theorem.3.2.8}\protected@file@percent }
\newlabel{fig:comic1}{{3.22}{76}{A hybrid grammar for text}{theorem.3.2.8}{}}
\citation{Penrose}
\citation{JS}
\citation{SelingerSurvey}
\citation{CKbook}
\citation{reutter_high-level_2019}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Text diagrams}{77}{section.3.3}\protected@file@percent }
\newlabel{sec:congraphas}{{3.3}{77}{Text diagrams}{section.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Preliminaries}{77}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Simple sentences as text diagrams}{78}{subsection.3.3.2}\protected@file@percent }
\newlabel{gramtograph}{{3.3.2}{78}{Simple sentences as text diagrams}{subsection.3.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Rewriting text diagrams}{82}{subsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Pronominal links in text diagrams}{82}{subsection.3.3.4}\protected@file@percent }
\newlabel{sec:prondiag}{{3.3.4}{82}{Pronominal links in text diagrams}{subsection.3.3.4}{}}
\newlabel{conv:onlyconnect}{{3.3.3}{84}{In text diagrams, only connectivity matters}{theorem.3.3.3}{}}
\citation{dorn_associative_2018}
\citation{reutter_high-level_2019}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.5}Phrase scope as phrase bubbles.}{88}{subsection.3.3.5}\protected@file@percent }
\newlabel{conv:phrscope}{{3.3.6}{89}{Rules for phrase scope}{theorem.3.3.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Text circuits}{92}{section.3.4}\protected@file@percent }
\newlabel{sec:circs}{{3.4}{92}{Text circuits}{section.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Definition}{92}{subsection.3.4.1}\protected@file@percent }
\citation{wilson_string_2022}
\citation{merry_reasoning_2014}
\citation{quick_-logic_2015}
\citation{zamdzhiev_rewriting_2017}
\newlabel{conv:sliding}{{3.4.1}{95}{}{theorem.3.4.1}{}}
\newpmemlabel{^_6}{97}
\@writefile{lof}{\contentsline {figure}{\numberline {3.23}{\ignorespaces Generating text circuits directly.}}{98}{theorem.3.4.3}\protected@file@percent }
\newlabel{fig:circuitgen}{{3.23}{98}{}{theorem.3.4.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Mathematical results}{99}{section.3.5}\protected@file@percent }
\newlabel{sec:thm}{{3.5}{99}{Mathematical results}{section.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Main Text Circuit Theorem}{99}{subsection.3.5.1}\protected@file@percent }
\newlabel{thm:main}{{3.5.1}{99}{Main Text Circuit Theorem}{subsection.3.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Refinements, extensions, conventions}{99}{subsection.3.5.2}\protected@file@percent }
\newlabel{sec:asscon}{{3.5.2}{99}{Refinements, extensions, conventions}{subsection.3.5.2}{}}
\newlabel{conv:wireorder}{{3.5.2}{99}{Wire ordering}{theorem.3.5.2}{}}
\newlabel{asm:exists}{{3.5.3}{101}{The verb \texttt {EXISTS}}{theorem.3.5.3}{}}
\newlabel{asm:conj}{{3.5.4}{102}{Sentence composition using \texttt {[\&]}}{theorem.3.5.4}{}}
\newlabel{conv:complement}{{3.5.5}{103}{Sentence composition within phrase scope, and the complementizer \texttt {[THAT]}}{theorem.3.5.5}{}}
\newlabel{asm:reflpron}{{3.5.6}{104}{Reflexive pronoun boxes}{theorem.3.5.6}{}}
\newlabel{ref:proncoherence}{{3.5.7}{105}{Coherence of reflexive pronoun boxes}{theorem.3.5.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Text diagrams to text circuits}{108}{subsection.3.5.3}\protected@file@percent }
\newlabel{graph2gateredux}{{3.5.3}{108}{Text diagrams to text circuits}{subsection.3.5.3}{}}
\newlabel{lem:shrinking}{{3.5.8}{109}{Shrinking reflexive pronouns}{theorem.3.5.8}{}}
\newlabel{cor:reflnorm}{{3.5.9}{109}{}{theorem.3.5.9}{}}
\newpmemlabel{^_7}{111}
\newlabel{lem:gatenorm}{{3.5.11}{111}{}{theorem.3.5.11}{}}
\newlabel{lem:diagnorm}{{3.5.12}{114}{}{theorem.3.5.12}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.3.0.1}Verbs with sentential complement}{114}{paragraph.3.5.3.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.3.0.2}Conjunctions}{115}{paragraph.3.5.3.0.2}\protected@file@percent }
\newpmemlabel{^_8}{116}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.4}Proof of Theorem}{116}{subsection.3.5.4}\protected@file@percent }
\newlabel{lem:function}{{3.5.14}{116}{}{theorem.3.5.14}{}}
\newlabel{lem:surj}{{3.5.15}{117}{}{theorem.3.5.15}{}}
\citation{GramEqs}
\citation{GramEqs}
\citation{FrobMeanI}
\citation{FrobMeanII}
\citation{GrefSadr}
\citation{KartsaklisSadrzadeh2014}
\citation{CLM}
\citation{CoeckeText}
\citation{CoeckeMeich}
\citation{IntWire}
\newpmemlabel{^_9}{121}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.5}Extending grammar by means of equations}{121}{subsection.3.5.5}\protected@file@percent }
\newlabel{ex:posspron}{{3.5.19}{123}{Possessive Pronouns}{theorem.3.5.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.24}{\ignorespaces Gate normalisation rewrites}}{128}{theorem.3.5.10}\protected@file@percent }
\newlabel{gatenormalisationrules}{{3.24}{128}{Text diagrams to text circuits}{theorem.3.5.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.25}{\ignorespaces Obtaining text circuits from text diagrams.}}{129}{theorem.3.5.13}\protected@file@percent }
\newlabel{fig:comic2}{{3.25}{129}{}{theorem.3.5.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.26}{\ignorespaces Textualisation of circuits, illustrated.}}{130}{theorem.3.5.16}\protected@file@percent }
\newlabel{fig:comic3}{{3.26}{130}{}{theorem.3.5.16}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Continuous relations: a palette for toy models}{131}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:contrel}{{4}{131}{Continuous relations: a palette for toy models}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Continuous Relations: A concept-compliant setting for text circuits}{132}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Why not use something already out there?}{133}{subsection.4.1.1}\protected@file@percent }
\newlabel{just:rel}{{4.1.1}{133}{Why not use something already out there?}{subsection.4.1.1}{}}
\newpmemlabel{^_10}{134}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Continuous Relations}{136}{section.4.2}\protected@file@percent }
\newlabel{defn:toprelation}{{4.2.4}{136}{Continuous Relation}{theorem.4.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}\textbf  {TopRel} diagrammatically}{137}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Relations that are always continuous}{137}{subsection.4.3.1}\protected@file@percent }
\newlabel{ex:nontop}{{4.4.1}{141}{A noncontinuous relation}{theorem.4.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Continuous Relations by examples}{141}{section.4.4}\protected@file@percent }
\newlabel{prop:states}{{4.4.3}{142}{}{theorem.4.4.3}{}}
\newlabel{prop:tests}{{4.4.4}{142}{}{theorem.4.4.4}{}}
\newlabel{prop:emptyrel}{{4.4.6}{142}{}{theorem.4.4.6}{}}
\newlabel{prop:fullrel}{{4.4.8}{142}{}{theorem.4.4.8}{}}
\newlabel{prop:bowtie}{{4.4.9}{142}{}{theorem.4.4.9}{}}
\newlabel{prop:func}{{4.4.10}{142}{}{theorem.4.4.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Regions of $\blacksquare $ in the image of the yellow point alone will be coloured yellow, and regions in the image of both yellow and cyan will be coloured green:}}{143}{theorem.4.4.18}\protected@file@percent }
\newlabel{fig:yellowgreen}{{4.1}{143}{Continuous Relations}{theorem.4.4.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Regions in the image of the cyan point alone cannot be open sets by continuity, so they are either points or lines. Points and lines in cyan must be surrounded by an open region in either yellow or green, or else we violate continuity (open sets in red).}}{143}{theorem.4.4.19}\protected@file@percent }
\newlabel{fig:cyan}{{4.2}{143}{Continuous Relations}{theorem.4.4.19}{}}
\newlabel{prop:idrel}{{4.4.12}{143}{}{theorem.4.4.12}{}}
\newlabel{prop:framehom}{{4.4.14}{143}{}{theorem.4.4.14}{}}
\newlabel{cor:homspace}{{4.4.15}{143}{}{theorem.4.4.15}{}}
\newlabel{lem:capideal}{{4.4.18}{143}{Partial functions are a $\cap $-ideal}{theorem.4.4.18}{}}
\newlabel{lem:edgecomplete}{{4.4.19}{143}{Any single edge can be extended to a continuous partial function}{theorem.4.4.19}{}}
\newlabel{prop:hombasis}{{4.4.20}{143}{}{theorem.4.4.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces A continuous relation $\mathcal  {S} \rightarrow \blacksquare $: "Flower and critter in a sunny field".}}{144}{theorem.4.4.19}\protected@file@percent }
\newlabel{fig:flower}{{4.3}{144}{Continuous Relations}{theorem.4.4.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces A continuous relation $\blacksquare \rightarrow \mathcal  {S}$: "still math?". Black lines and dots indicate gaps.}}{144}{theorem.4.4.19}\protected@file@percent }
\newlabel{fig:shitpost}{{4.4}{144}{Continuous Relations}{theorem.4.4.19}{}}
\newpmemlabel{^_11}{144}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Hasse diagram of all continuous relations from the Sierpi\'{n}ski space to itself. Each relation is depicted left to right, and inclusion order is bottom-to-top. Relations that form the topological basis are boxed.}}{145}{theorem.4.4.20}\protected@file@percent }
\newlabel{fig:hassesierpinski}{{4.5}{145}{Continuous Relations}{theorem.4.4.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces  continuous functions $[0,1] \rightarrow \blacksquare $ follow the na\"{i}ve notion of continuity: a line one can draw on paper without lifting the pen off the page. }}{146}{theorem.4.4.20}\protected@file@percent }
\newlabel{fig:contline}{{4.6}{146}{Continuous Relations}{theorem.4.4.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces  So a continuous partial function is \texttt  {"(countably) many (open-ended) lines, each of which one can draw on paper without lifting the pen off the page."} }}{146}{theorem.4.4.20}\protected@file@percent }
\newlabel{fig:contline}{{4.7}{146}{Continuous Relations}{theorem.4.4.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces We can control the thickness of the brushstroke, by taking the union of (uncountably) many lines.}}{146}{theorem.4.4.20}\protected@file@percent }
\newlabel{fig:thickbrush}{{4.8}{146}{Continuous Relations}{theorem.4.4.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Assign the visible spectrum of light to $[0,1]$. Colour open sets according to perceptual addition of light, computing brightness by normalising the measure of the open set.}}{146}{theorem.4.4.20}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Like it or not, a continuous relation $[0,1] \rightarrow \blacksquare $: "The Starry Night", by Vincent van Gogh.}}{147}{theorem.4.4.20}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Populating space with shapes using sticky spiders}{147}{section.4.5}\protected@file@percent }
\newlabel{sec:stickyspider}{{4.5}{147}{Populating space with shapes using sticky spiders}{section.4.5}{}}
\newpmemlabel{^_12}{147}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}When does an object have a spider (or something close to one)?}{147}{subsection.4.5.1}\protected@file@percent }
\newlabel{ex:compnotspider}{{4.5.2}{147}{The copy-compare spiders of $\mathbf {Rel}$ are not always continuous}{theorem.4.5.2}{}}
\newlabel{prop:copydiscrete}{{4.5.3}{147}{}{theorem.4.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces The generators (in dashed boxes) and relations that make a spider. When the spider satisfies in addition the three inequalities b1-3, we call it a \textbf  {relation-spider}.}}{148}{section.4.5}\protected@file@percent }
\newlabel{fig:spiderbicate}{{4.11}{148}{Populating space with shapes using sticky spiders}{section.4.5}{}}
\newlabel{defn:stickyspider}{{4.5.5}{149}{Sticky spiders}{theorem.4.5.5}{}}
\newlabel{prop:splitmeanssticky}{{4.5.7}{151}{Every idempotent that splits through a discrete topology gives a sticky spider}{theorem.4.5.7}{}}
\newlabel{thm:stickygraphical}{{4.5.8}{153}{}{theorem.4.5.8}{}}
\newlabel{prop:counitdelete}{{4.5.9}{155}{comult/copy implies counit/delete}{theorem.4.5.9}{}}
\newlabel{lem:allornothing}{{4.5.10}{156}{All-or-Nothing}{theorem.4.5.10}{}}
\newlabel{prop:epointcopy}{{4.5.11}{158}{$e$ of any point is $e$-copiable}{theorem.4.5.11}{}}
\newlabel{prop:copiablebasis}{{4.5.12}{159}{The unit is the union of all $e$-copiables}{theorem.4.5.12}{}}
\newlabel{prop:decompidem}{{4.5.13}{160}{$e$-copiable decomposition of $e$}{theorem.4.5.13}{}}
\newlabel{prop:decompcounit}{{4.5.14}{161}{$e$-copiable decomposition of counit}{theorem.4.5.14}{}}
\newlabel{lem:match}{{4.5.15}{162}{$e$-copiables are orthogonal under multiplication}{theorem.4.5.15}{}}
\newlabel{lem:comatch}{{4.5.17}{164}{Co-match}{theorem.4.5.17}{}}
\newlabel{lem:ecopyfixpoint}{{4.5.18}{165}{e-copiables are e-fixpoints}{theorem.4.5.18}{}}
\newlabel{lem:ecopynormal}{{4.5.19}{166}{$e$-copiables are normal}{theorem.4.5.19}{}}
\newlabel{prop:decompmult}{{4.5.20}{167}{$e$-copiable decomposition of multiplication}{theorem.4.5.20}{}}
\newlabel{prop:decompcomult}{{4.5.21}{168}{$e$-copiable decomposition of comultiplication}{theorem.4.5.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Topological concepts in flatland via \textbf  {TopRel}}{171}{section.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Shapes and places}{171}{subsection.4.6.1}\protected@file@percent }
\newlabel{sec:shapes}{{4.6.1}{171}{Shapes and places}{subsection.4.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}The unit interval}{173}{subsection.4.6.2}\protected@file@percent }
\newlabel{sec:interval}{{4.6.2}{173}{The unit interval}{subsection.4.6.2}{}}
\newlabel{thm:Friedman}{{4.6.7}{173}{Friedman}{theorem.4.6.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}Displacing shapes}{176}{subsection.4.6.3}\protected@file@percent }
\newlabel{sec:displace}{{4.6.3}{176}{Displacing shapes}{subsection.4.6.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.4}Moving shapes}{179}{subsection.4.6.4}\protected@file@percent }
\newlabel{sec:moving}{{4.6.4}{179}{Moving shapes}{subsection.4.6.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.5}Rigid motion}{183}{subsection.4.6.5}\protected@file@percent }
\newlabel{sec:rigidmotion}{{4.6.5}{183}{Rigid motion}{subsection.4.6.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.6}Modelling linguistic topological concepts}{186}{subsection.4.6.6}\protected@file@percent }
\newlabel{sec:topconcept}{{4.6.6}{186}{Modelling linguistic topological concepts}{subsection.4.6.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.7}States, actions, manner}{191}{subsection.4.6.7}\protected@file@percent }
\newlabel{sec:statesactions}{{4.6.7}{191}{States, actions, manner}{subsection.4.6.7}{}}
\newlabel{cons:morph}{{4.6.11}{195}{Morphing sticky spiders with homotopies}{theorem.4.6.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Mathematician's endnotes}{198}{section.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.1}The category \textbf  {TopRel}}{198}{subsection.4.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.2}Symmetric Monoidal structure}{198}{subsection.4.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.3}Rig category structure}{199}{subsection.4.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.4}\textbf  {TopRel} and \textbf  {Rel} are related by a free-forgetful adjunction}{200}{subsection.4.7.4}\protected@file@percent }
\newlabel{lem:disccont}{{4.7.7}{200}{Any relation $R$ between discrete topologies is continuous}{theorem.4.7.7}{}}
\newlabel{lem:idadj}{{4.7.10}{200}{$RL = 1_{\textbf {Rel}}$}{theorem.4.7.10}{}}
\newlabel{lem:coarse}{{4.7.12}{200}{Coarsening is a continuous relation}{theorem.4.7.12}{}}
\newlabel{prop:reladj}{{4.7.13}{201}{$L \dashv R$}{theorem.4.7.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.5}Why not Span(\textbf  {Top})?}{202}{subsection.4.7.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.6}Why not a Kleisli construction on \textbf  {Top}?}{202}{subsection.4.7.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.7}Where is the topology coming from?}{203}{subsection.4.7.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.8}Why are continuous relations worth the trouble?}{203}{subsection.4.7.8}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Sketches of the shape of language}{205}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:sketches}{{5}{205}{Sketches of the shape of language}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Lassos for generalised anaphora}{206}{section.5.1}\protected@file@percent }
\newlabel{sec:lassos}{{5}{216}{Sketches of the shape of language}{theorem.5.1.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}(Im)possibility results for learning text circuits from data}{217}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Approximating Text Circuits with deterministic neural nets}{217}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Text circuits with unbounded depth and width}{222}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Text circuits of unbounded width in noncartesian settings}{223}{subsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}A value proposition for quantum machine learning}{224}{subsection.5.2.4}\protected@file@percent }
\newlabel{sec:learn}{{5}{225}{Sketches of the shape of language}{subsection.5.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Modelling metaphor}{226}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Orders, Temperature, Colour, Mood}{226}{subsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Complex conceptual structure}{226}{subsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}}{227}{subsection.5.3.3}\protected@file@percent }
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\ttl@finishall
\gdef \@abspage@last{228}
