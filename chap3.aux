\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\newpmemlabel{^_1}{1}
\newlabel{defn:lex}{{0.1.1}{4}{Lexicon}{theorem.0.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {How to read the diagrams in this section:} we will be making heavy use of pink and purple bubbles as frames to construct circuits. We will depict the bubbles horizontally, as we are permitted to by compact closure, or by reading diagrams with slightly skewed axes.}}{4}{theorem.0.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {0.1}A generative grammar for text circuits}{4}{section.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.1}A circuit-growing grammar}{4}{subsection.0.1.1}\protected@file@percent }
\newpmemlabel{^_2}{5}
\newpmemlabel{^_3}{5}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces In this toy example, obtaining the same rewrite that connects the two yellow nodes with a purple wire using only graph-theoretically-local rewrites could potentially require an infinite family of rules for all possible configurations of pink and cyan nodes that separate the yellow, or would otherwise require disturbing other nodes in the rewrite process. In our setting, strong compact closure homotopies handle navigation between different spatial presentations so that a single rewrite rule suffices: the source and target notated by dotted-black circles. Despite the expressive economy and power of finitely presented signatures, we cannot "computationally cheat" graph isomorphism: formally we must supply the compact-closure homotopies as part of the rewrite, absorbed and hidden here by the $\simeq $ notation.}}{5}{theorem.0.1.1}\protected@file@percent }
\newlabel{fig:locality}{{2}{5}{A circuit-growing grammar}{theorem.0.1.1}{}}
\newlabel{dfn:simpCSG}{{0.1.2}{6}{CSG for simple sentences}{theorem.0.1.2}{}}
\newlabel{prop:simpsent}{{0.1.3}{6}{}{theorem.0.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.2}Simple sentences}{6}{subsection.0.1.2}\protected@file@percent }
\newlabel{dfn:sentCSG}{{0.1.4}{7}{Sentence structure}{theorem.0.1.4}{}}
\newlabel{prop:compsent}{{0.1.5}{7}{}{theorem.0.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.3}Complex sentences}{7}{subsection.0.1.3}\protected@file@percent }
\newpmemlabel{^_4}{7}
\newpmemlabel{^_5}{7}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The dotted-blue wires do not contentfully interact with anything else, but this noninteraction disallows overgeneration cases where adpositional phrases might interject between \texttt  {SCV} verbs and their sentential complement, e.g. \leavevmode {\color  {red}\texttt  {Alice sees \underline  {at lunch} Bob drink}}. The dotted-blue wires also indicate a diagrammatic strategy for extensions to accommodate noun phrases, to be explored later.}}{7}{subsection.0.1.3}\protected@file@percent }
\newlabel{fig:sentbestiary}{{3}{7}{Complex sentences}{subsection.0.1.3}{}}
\newpmemlabel{^_6}{7}
\newpmemlabel{^_8}{7}
\newpmemlabel{^_7}{8}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  \begin  {example}[\texttt  {sober} $\alpha $ \texttt  {sees drunk} $\beta $ \texttt  {clumsily dance.}] Now we can see our rewrites in action for sentences. As a matter of convention -- reflected in how the various pass- rules do not interact with labels -- we assume that labelling occurs after all of the words are saturated. We have still not introduced rules for labelling nouns: we delay their consideration until we have settled coreferential structure. For now they are labelled informally with greeks. \end  {example} }}{8}{theorem.0.1.5}\protected@file@percent }
\newlabel{fig:soberA}{{4}{8}{Complex sentences}{theorem.0.1.6}{}}
\newpmemlabel{^_9}{9}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  \begin  {example}[$\alpha $ \texttt  {laughs at} $\beta $] Adpositions form by first sprouting and connecting tendrils under the surface. Because the tendril- and pass- rules are bidirectional, extraneous tendrils can always be retracted, and failed attempts for verbs to find an adpositional unsaturated noun argument can be undone. Though this seems computationally wasteful, it is commonplace in generative grammars to have the grammar overgenerate and later define the set of sentences by restriction, which is reasonable so long as computing the restriction is not computationally hard. In our case, observe that once a verb has been introduced and its argument nouns have been saturated, only the introduction of adpositions can saturate additionally introduced unsaturated nouns. Therefore we may define the finished sentences of the circuit-growing grammar to be those that e.g. contain no unsaturated nodes on the surface, which is a very plausible linear-time check by traversing the surface. \end  {example} }}{9}{theorem.0.1.6}\protected@file@percent }
\newlabel{fig:Alaughs}{{5}{9}{Complex sentences}{theorem.0.1.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.4}Text structure and noun-coreference}{10}{subsection.0.1.4}\protected@file@percent }
\newpmemlabel{^_10}{10}
\newpmemlabel{^_11}{10}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Only considering words, text is just a list of sentences. However, for our purposes, text additionally has \emph  {coreferential structure}. Ideally, we would like to connect "the same noun" from distinct sentences as we would circuits.}}{10}{subsection.0.1.4}\protected@file@percent }
\newpmemlabel{^_12}{10}
\newpmemlabel{^_13}{10}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces We choose the convention of connecting from left-to-right and from bottom-to-top, so that we might read circuits as we would text: the components corresponding to words will be arranged left-to-right and top-to-bottom. Connecting nouns across distinct sentences presents no issue, but a complication arises when connecting nouns within the same sentence as with reflexive pronouns e.g. \texttt  {Alice likes herself}.}}{10}{subsection.0.1.4}\protected@file@percent }
\newpmemlabel{^_14}{10}
\newpmemlabel{^_15}{10}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Reflexive coreference would violate of the processivity condition of string diagrams for symmetric monoidal categories. Not all symmetric monoidal categories possess the appropriate structure to interpret such reflexive pronouns, but there exist interpretative options. From left to right in roughly decreasing stringency, compact closed categories are the most direct solution. More weakly, traced symmetric monoidal categories also suffice. If there are no traces, so long as the noun wire possesses a monoid and comonoid, a convolution works. If all else fails, one can just specify a new gate. We will define coreference structure to exclude such reflexive coreference and revisit the issue as an extension.}}{10}{subsection.0.1.4}\protected@file@percent }
\newlabel{fig:reflcomp}{{8}{10}{Text structure and noun-coreference}{subsection.0.1.4}{}}
\newlabel{prop:linkedlist}{{0.1.8}{11}{}{theorem.0.1.8}{}}
\newpmemlabel{^_16}{11}
\newpmemlabel{^_17}{12}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces At this point, it is worth establishing some terminology about the kinds of unsaturated nouns we have in play. The kinds of nouns are distinguished by their tails. \emph  {Lonely} nouns have no coreferences, their tails connect to nothing. \emph  {Head} nouns have a forward coreference in text; they have two tails, one that connects to nothing and the other to a noun later in text. \emph  {Middle} nouns have a forward and backward coreference; they have two tails, one that connects to a noun in some preceding sentence, and one that connects forward to a noun in a succeeding sentence. \emph  {Foot} nouns only have a backward coreference; they have a single tail connecting to a noun in some preceding sentence.}}{12}{subsection.0.1.4}\protected@file@percent }
\newlabel{fig:nounkinds}{{9}{12}{Text structure and noun-coreference}{subsection.0.1.4}{}}
\newpmemlabel{^_18}{12}
\newpmemlabel{^_20}{12}
\newpmemlabel{^_22}{12}
\newpmemlabel{^_24}{12}
\newpmemlabel{^_19}{13}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces \begin  {color}{red}FILL IN DESCRIPTIONS \end  {color}\xspace  }}{13}{theorem.0.1.9}\protected@file@percent }
\newlabel{fig:corefex1}{{10}{13}{Text structure and noun-coreference}{theorem.0.1.9}{}}
\newpmemlabel{^_21}{13}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces \begin  {color}{red}FILL IN DESCRIPTIONS \end  {color}\xspace  }}{13}{theorem.0.1.9}\protected@file@percent }
\newlabel{fig:corefex2}{{11}{13}{Text structure and noun-coreference}{theorem.0.1.9}{}}
\newpmemlabel{^_23}{13}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces \begin  {color}{red}FILL IN DESCRIPTIONS \end  {color}\xspace  }}{13}{theorem.0.1.9}\protected@file@percent }
\newlabel{fig:corefex3}{{12}{13}{Text structure and noun-coreference}{theorem.0.1.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.5}Extensions I: relative and reflexive pronouns}{13}{subsection.0.1.5}\protected@file@percent }
\newpmemlabel{^_25}{14}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces \begin  {color}{red}FILL IN DESCRIPTIONS \end  {color}\xspace  }}{14}{theorem.0.1.9}\protected@file@percent }
\newlabel{fig:corefex4}{{13}{14}{Text structure and noun-coreference}{theorem.0.1.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.6}Extensions II: grammar equations}{15}{subsection.0.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.7}Extensions III: higher-order modifiers}{15}{subsection.0.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.8}Equivalence to internal wirings}{15}{subsection.0.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.9}Text circuit theorem}{15}{subsection.0.1.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.10}Related work}{15}{subsection.0.1.10}\protected@file@percent }
\citation{wilson_string_2022}
\citation{merry_reasoning_2014,quick_-logic_2015,zamdzhiev_rewriting_2017}
\@writefile{toc}{\contentsline {section}{\numberline {0.2}Text circuits: details, demos, developments}{16}{section.0.2}\protected@file@percent }
\newlabel{sec:circs}{{0.2}{16}{Text circuits: details, demos, developments}{section.0.2}{}}
\newlabel{conv:sliding}{{0.2.1}{17}{}{theorem.0.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Sentences correspond to filled gates, boxes with fixed arity correspond to first-order modifiers such as adverbs and adpositions, and boxes with variable arity correspond to sentential-level modifiers such as conjunctions and verbs with sentential complements. Composition by connecting wires corresponds to identifying coreferences in discourse, and composition by nesting corresponds to grammatical structure within sentences.}}{18}{theorem.0.2.2}\protected@file@percent }
\newlabel{fig:circuitgen}{{14}{18}{Text circuits: details, demos, developments}{theorem.0.2.2}{}}
\ttl@finishall
\gdef \@abspage@last{18}
