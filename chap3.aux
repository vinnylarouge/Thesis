\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\newpmemlabel{^_1}{1}
\newlabel{defn:lex}{{0.1.1}{4}{Lexicon}{theorem.0.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {How to read the diagrams in this section:} we will be making heavy use of pink and purple bubbles as frames to construct circuits. We will depict the bubbles horizontally, as we are permitted to by compact closure, or by reading diagrams with slightly skewed axes.}}{4}{theorem.0.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {0.1}A generative grammar for text circuits}{4}{section.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.1}A circuit-growing grammar}{4}{subsection.0.1.1}\protected@file@percent }
\newpmemlabel{^_2}{5}
\newpmemlabel{^_3}{5}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces In this toy example, obtaining the same rewrite that connects the two yellow nodes with a purple wire using only graph-theoretically-local rewrites could potentially require an infinite family of rules for all possible configurations of pink and cyan nodes that separate the yellow, or would otherwise require disturbing other nodes in the rewrite process. In our setting, strong compact closure homotopies handle navigation between different spatial presentations so that a single rewrite rule suffices: the source and target notated by dotted-black circles. Despite the expressive economy and power of finitely presented signatures, we cannot "computationally cheat" graph isomorphism: formally we must supply the compact-closure homotopies as part of the rewrite, absorbed and hidden here by the $\simeq $ notation.}}{5}{theorem.0.1.1}\protected@file@percent }
\newlabel{fig:locality}{{2}{5}{A circuit-growing grammar}{theorem.0.1.1}{}}
\newlabel{dfn:simpCSG}{{0.1.2}{6}{CSG for simple sentences}{theorem.0.1.2}{}}
\newlabel{prop:simpsent}{{0.1.3}{6}{}{theorem.0.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.2}Simple sentences}{6}{subsection.0.1.2}\protected@file@percent }
\newlabel{dfn:sentCSG}{{0.1.4}{7}{Sentence structure}{theorem.0.1.4}{}}
\newlabel{prop:compsent}{{0.1.5}{7}{}{theorem.0.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.3}Complex sentences}{7}{subsection.0.1.3}\protected@file@percent }
\newpmemlabel{^_4}{7}
\newpmemlabel{^_5}{7}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The dotted-blue wires do not contentfully interact with anything else, but this noninteraction disallows overgeneration cases where adpositional phrases might interject between \texttt  {SCV} verbs and their sentential complement, e.g. \leavevmode {\color  {red}\texttt  {Alice sees \underline  {at lunch} Bob drink}}. The dotted-blue wires also indicate a diagrammatic strategy for extensions to accommodate noun phrases, to be explored later.}}{7}{subsection.0.1.3}\protected@file@percent }
\newlabel{fig:sentbestiary}{{3}{7}{Complex sentences}{subsection.0.1.3}{}}
\newpmemlabel{^_6}{7}
\newpmemlabel{^_8}{7}
\newpmemlabel{^_7}{8}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  \begin  {example}[\texttt  {sober} $\alpha $ \texttt  {sees drunk} $\beta $ \texttt  {clumsily dance.}] Now we can see our rewrites in action for sentences. As a matter of convention -- reflected in how the various pass- rules do not interact with labels -- we assume that labelling occurs after all of the words are saturated. We have still not introduced rules for labelling nouns: we delay their consideration until we have settled coreferential structure. For now they are labelled informally with greeks. \end  {example} }}{8}{theorem.0.1.5}\protected@file@percent }
\newlabel{fig:soberA}{{4}{8}{Complex sentences}{theorem.0.1.6}{}}
\newpmemlabel{^_9}{9}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  \begin  {example}[$\alpha $ \texttt  {laughs at} $\beta $] Adpositions form by first sprouting and connecting tendrils under the surface. Because the tendril- and pass- rules are bidirectional, extraneous tendrils can always be retracted, and failed attempts for verbs to find an adpositional unsaturated noun argument can be undone. Though this seems computationally wasteful, it is commonplace in generative grammars to have the grammar overgenerate and later define the set of sentences by restriction, which is reasonable so long as computing the restriction is not computationally hard. In our case, observe that once a verb has been introduced and its argument nouns have been saturated, only the introduction of adpositions can saturate additionally introduced unsaturated nouns. Therefore we may define the finished sentences of the circuit-growing grammar to be those that e.g. contain no unsaturated nodes on the surface, which is a very plausible linear-time check by traversing the surface. \end  {example} }}{9}{theorem.0.1.6}\protected@file@percent }
\newlabel{fig:Alaughs}{{5}{9}{Complex sentences}{theorem.0.1.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.4}Text structure and noun-coreference}{10}{subsection.0.1.4}\protected@file@percent }
\newpmemlabel{^_10}{10}
\newpmemlabel{^_11}{10}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Only considering words, text is just a list of sentences. However, for our purposes, text additionally has \emph  {coreferential structure}. Ideally, we would like to connect "the same noun" from distinct sentences as we would circuits.}}{10}{subsection.0.1.4}\protected@file@percent }
\newpmemlabel{^_12}{10}
\newpmemlabel{^_13}{10}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces We choose the convention of connecting from left-to-right and from bottom-to-top, so that we might read circuits as we would text: the components corresponding to words will be arranged left-to-right and top-to-bottom. Connecting nouns across distinct sentences presents no issue, but a complication arises when connecting nouns within the same sentence as with reflexive pronouns e.g. \texttt  {Alice likes herself}.}}{10}{subsection.0.1.4}\protected@file@percent }
\newpmemlabel{^_14}{10}
\newpmemlabel{^_15}{10}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Reflexive coreference would violate of the processivity condition of string diagrams for symmetric monoidal categories. Not all symmetric monoidal categories possess the appropriate structure to interpret such reflexive pronouns, but there exist interpretative options. From left to right in roughly decreasing stringency, compact closed categories are the most direct solution. More weakly, traced symmetric monoidal categories also suffice. If there are no traces, so long as the noun wire possesses a monoid and comonoid, a convolution works. If all else fails, one can just specify a new gate. We will define coreference structure to exclude such reflexive coreference and revisit the issue as an extension.}}{10}{subsection.0.1.4}\protected@file@percent }
\newlabel{fig:reflcomp}{{8}{10}{Text structure and noun-coreference}{subsection.0.1.4}{}}
\newpmemlabel{^_16}{11}
\newpmemlabel{^_18}{11}
\newpmemlabel{^_20}{11}
\newpmemlabel{^_22}{11}
\newpmemlabel{^_24}{11}
\newpmemlabel{^_26}{11}
\newpmemlabel{^_17}{12}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces At this point, it is worth establishing some terminology about the kinds of unsaturated nouns we have in play. The kinds of nouns are distinguished by their tails. \emph  {Lonely} nouns have no coreferences, their tails connect to nothing. \emph  {Head} nouns have a forward coreference in text; they have two tails, one that connects to nothing and the other to a noun later in text. \emph  {Middle} nouns have a forward and backward coreference; they have two tails, one that connects to a noun in some preceding sentence, and one that connects forward to a noun in a succeeding sentence. \emph  {Foot} nouns only have a backward coreference; they have a single tail connecting to a noun in some preceding sentence.}}{12}{subsection.0.1.4}\protected@file@percent }
\newlabel{fig:nounkinds}{{9}{12}{Text structure and noun-coreference}{subsection.0.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.5}Text circuit theorem}{12}{subsection.0.1.5}\protected@file@percent }
\newpmemlabel{^_19}{13}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The $n \in \mathbf  {N}$ notation indicates a family of rewrites (and generators) for each noun in the lexicon. Link-label assigns a noun to a diagrammatically linked collection of coreferent nouns, and link-propagation is a case analysis that copies a link label and distributes is across coreferent nouns. Link-rise is a case analysis to connect labels to the surface, and finally \texttt  {N}-label allows a saturated noun to inherit the label of its coreference class, which may either be a noun \texttt  {n} or a pronoun appropriate for the noun, notated $^\texttt  {*}\texttt  {n}$}}{13}{subsection.0.1.4}\protected@file@percent }
\newpmemlabel{^_21}{14}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces We start the derivation by setting up the sentence structure using \texttt  {S}- and \texttt  {SCV}-intro rules, and two instances of \texttt  {N}-intro, one for Alice, and one for Bob. Observe how the \texttt  {N}-intro for Bob occurs within the subsentence scoped over by the \texttt  {SCV}-rule.}}{14}{theorem.0.1.8}\protected@file@percent }
\newlabel{fig:corefex1}{{11}{14}{Text structure and noun-coreference}{theorem.0.1.8}{}}
\newpmemlabel{^_23}{14}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces By homotopy, we can rearrange the previous diagram to obtain the source of the linked-\texttt  {N}-intro rewrite in the dashed-box visual aid. Observe how we drag in the root of what is to be Alice's wire. Then we use the \texttt  {IV}-intro in the second sentence, which sets up the surface structure \texttt  {she laughs}, and the deep structure for bookkeeping that \texttt  {she} refers to \texttt  {Alice}.}}{14}{theorem.0.1.8}\protected@file@percent }
\newlabel{fig:corefex2}{{12}{14}{Text structure and noun-coreference}{theorem.0.1.8}{}}
\newpmemlabel{^_25}{14}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces By homotopy again, we can do the same for Bob, this time setting up for the $\gamma $ variant of linked-\texttt  {N}-intro which handles the case when the spawning noun is within the scope of an SCV. Then by applying a series of $\texttt  {N}_\uparrow $-swaps, the unsaturated noun is placed to the right of the intransitive verb phrase.}}{14}{theorem.0.1.8}\protected@file@percent }
\newlabel{fig:corefex3}{{13}{14}{Text structure and noun-coreference}{theorem.0.1.8}{}}
\newpmemlabel{^_27}{15}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces We've already done the surface derivation for the two sentences separately in Figures \ref  {fig:soberA} and \ref  {fig:Alaughs}; since neither of those derivations touch the roots of noun-wires, we can emulate those derivations and skip ahead to the first diagram. }}{15}{theorem.0.1.8}\protected@file@percent }
\newlabel{fig:corefex4}{{14}{15}{Text structure and noun-coreference}{theorem.0.1.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Nouns are represented by wires, each `distinct' noun having its own wire.}}{16}{theorem.0.1.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces We represent adjectives, intransitive verbs, and transitive verbs by gates acting on noun-wires. Since a transitive verb has both a subject and an object noun, that will then be two noun-wires, while adjectives and intransitive verbs only have one.}}{16}{theorem.0.1.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Adverbs, which modify verbs, we represent as boxes with holes in them, with a number of dangling wires in the hole indicating the shape of gate expected, and these should match the input- and output-wires of the box with the whole.}}{16}{theorem.0.1.9}\protected@file@percent }
\newlabel{prop:linkedlist}{{0.1.12}{16}{}{theorem.0.1.12}{}}
\newlabel{prop:norefl}{{0.1.13}{16}{}{theorem.0.1.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Similarly, adpositions also modify verbs, by moreover adding another noun-wire to the right.}}{17}{theorem.0.1.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces For verbs that take sentential complements and conjunctions, we have families of boxes to accommodate input circuits of all sizes. They add another noun-wire to the left of a circuit.}}{17}{theorem.0.1.9}\protected@file@percent }
\newlabel{cons:wirejoin}{{0.1.14}{17}{Text to circuit}{theorem.0.1.14}{}}
\newpmemlabel{^_28}{17}
\newpmemlabel{^_29}{17}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces We turn finished text diagrams into text circuits by operating \emph  {in situ}, with extra rules outside the grammatical system that handle connecting noun wires. }}{17}{theorem.0.1.14}\protected@file@percent }
\newpmemlabel{^_30}{17}
\newpmemlabel{^_31}{17}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces  In the first step, by Lemmas \ref  {prop:linkedlist} and \ref  {prop:norefl}, we can always rearrange a finished text diagram such that the noun wires are processive.\\ \par In the second step, use the first rewrite of Construction \ref  {cons:wirejoin} to prepare the wires for connection.\\ \par In the third step, we just ignore the existence of the bubble-scaffolding and the loose scalars. We could in principle add more rewrites to melt the scaffolding away if we wanted, but who cares?\\ \par In the fourth step, we apply the second and third rewrites of Construction \ref  {cons:wirejoin} to connect the wires and eliminate nodules underneath labels. We can also straighten up the wires a bit and make them look proper.\\ \par At this point, we're actually done, because the resulting diagram \emph  {is already a text circuit up to a choice of notation}. }}{17}{theorem.0.1.14}\protected@file@percent }
\newlabel{prop:text2circ}{{0.1.15}{17}{Finished text diagrams yield unique-up-to-processive-isotopy text circuits}{theorem.0.1.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Conjunctions are boxes that take two circuits which might share labels on some wires.}}{18}{theorem.0.1.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Of course filled up boxes are just gates.}}{18}{theorem.0.1.9}\protected@file@percent }
\newpmemlabel{^_32}{18}
\newpmemlabel{^_33}{18}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces  \begin  {convention}[Wire twisting] \end  {convention} Wires are labelled by nouns. We consider two circuits the same if their gate-connectivity is the same. In particular, this means that we can eliminate unnecessary twists in wires to obtain diagrammatically simpler representations. }}{18}{theorem.0.1.16}\protected@file@percent }
\newlabel{conv:twist}{{25}{18}{Text circuit theorem}{theorem.0.1.17}{}}
\newpmemlabel{^_34}{18}
\newpmemlabel{^_35}{18}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces  \begin  {convention}[Sliding] \end  {convention} Since only gate-connectivity matters, we consider circuits the same if all that differs is the horizontal positioning of gates composed in parallel. \begin  {convention}[Reading text circuits] \end  {convention} Text circuits ought to be presented so that they can be read from top to bottom and from left to right, like English text. }}{18}{theorem.0.1.17}\protected@file@percent }
\newlabel{conv:reading}{{26}{18}{Text circuit theorem}{theorem.0.1.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Gates compose sequentially by matching labels on some of their noun-wires and in parallel when they share no noun-wires, to give \underline  {text circuits}.}}{19}{theorem.0.1.9}\protected@file@percent }
\newlabel{conv:gaps}{{0.1.20}{19}{Arbitary vs. fixed holes}{theorem.0.1.20}{}}
\newlabel{conv:and}{{0.1.21}{19}{Contentless conjunctions}{theorem.0.1.21}{}}
\newlabel{conv:exists}{{0.1.22}{19}{Lonely wires}{theorem.0.1.22}{}}
\newlabel{prop:circ2text}{{0.1.23}{20}{Circuit to text}{theorem.0.1.23}{}}
\newpmemlabel{^_36}{20}
\newpmemlabel{^_37}{20}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Starting with a circuit, we may use Convention \ref  {conv:twist} to arrange the circuit into alternating slices of twisting wires and (possibly tensored) circuits, and this arrangement recurses within boxes. Slices with multiple tensored gates will be treated using Convention \ref  {conv:and}. By convention \ref  {conv:exists}, we decorate lonely wires with formal \texttt  {exists} gates, as in the \texttt  {Frank sees} box. Observe how verbs with sentential complement are depicted with grey gaps, whereas the adverb and adposition combination of \texttt  {Mac crazily laughs at Cricket} is gapless, according to Convention \ref  {conv:gaps}.}}{20}{theorem.0.1.23}\protected@file@percent }
\newpmemlabel{^_38}{20}
\newpmemlabel{^_40}{20}
\newpmemlabel{^_42}{20}
\newpmemlabel{^_44}{20}
\newpmemlabel{^_39}{21}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces We then linearise the slices, representing top-to-bottom composition as left-to-right. Twist layers are eliminated, replaced instead by dotted connections indicating processive connectivity. The dashed vertical line distinguishes slices. This step of the procedure always behaves well, guaranteed by Proposition \ref  {prop:linkedlist}. Noun wires that do not participate in earlier slices can be shifted right until the slice they are introduced.}}{21}{theorem.0.1.23}\protected@file@percent }
\newpmemlabel{^_41}{21}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces We recurse the linearisation procedure within boxes until there are no more sequentially composed gates. The linearisation procedure evidently terminates for finite text circuits. At this point, we have abstracted away connectivity data, and we are left with individual gates.}}{21}{theorem.0.1.23}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.6}Extensions I: relative and reflexive pronouns}{21}{subsection.0.1.6}\protected@file@percent }
\newpmemlabel{^_43}{22}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces By Proposition \ref  {prop:compsent}, gates are equivalent to sentences up to notation, so we swap notations \emph  {in situ}. Conventions \ref  {conv:and} and \ref  {conv:exists} handle the edge cases of parallel gates and lonely wires. Observe that the blue-dotted wiring in text diagrams delineates the contents of boxes that accept sentences.}}{22}{theorem.0.1.23}\protected@file@percent }
\newpmemlabel{^_45}{22}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Recursing notation swaps outwards and connecting left-to-right slices as sentence-bubbles connect yields a text circuit, up to the inclusion of rewrites from Conventions \ref  {conv:and} and \ref  {conv:exists}: applying the reverse of those rewrites and the reverse of text-diagram rewrites yields a valid text-diagram derivation, by Propositions \ref  {prop:compsent} and \ref  {prop:linkedlist}.}}{22}{theorem.0.1.23}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.7}Extensions II: grammar equations}{23}{subsection.0.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.8}Extensions III: higher-order modifiers}{23}{subsection.0.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.9}Equivalence to internal wirings}{23}{subsection.0.1.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1.10}Related work}{23}{subsection.0.1.10}\protected@file@percent }
\citation{wilson_string_2022}
\citation{merry_reasoning_2014,quick_-logic_2015,zamdzhiev_rewriting_2017}
\@writefile{toc}{\contentsline {section}{\numberline {0.2}Text circuits: details, demos, developments}{24}{section.0.2}\protected@file@percent }
\newlabel{sec:circs}{{0.2}{24}{Text circuits: details, demos, developments}{section.0.2}{}}
\ttl@finishall
\gdef \@abspage@last{25}
