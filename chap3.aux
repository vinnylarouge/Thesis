\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\newpmemlabel{^_1}{1}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Text circuits for syntax}{5}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:textcircuits}{{1}{5}{Text circuits for syntax}{chapter.1}{}}
\citation{wilson_string_2022}
\citation{merry_reasoning_2014,quick_-logic_2015,zamdzhiev_rewriting_2017}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Text circuits: details, demos, developments}{6}{section.1.1}\protected@file@percent }
\newlabel{sec:circs}{{1.1}{6}{Text circuits: details, demos, developments}{section.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Avenues I: syncategorematicity as distributivity}{7}{subsection.1.1.1}\protected@file@percent }
\newpmemlabel{^_2}{7}
\newpmemlabel{^_3}{7}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces  \begin  {example}[\textbf  {Syncategorematicity I}] \[\texttt  {Alice \underline  {and} Bob drink}\] \end  {example} \emph  {Syncategorematic} words are roughly those that have contextually-dependent semantics. Their dependency is usually predicated on the grammatical type of their arguments. In our terms, since we consider the semantics of text circuits to be underpinned by monoidal functors that reify the circuits in a target category, syncategorematic words such as \texttt  {and} may be treated as distributive laws. Here \texttt  {and} occurs as a conjunction of nouns and is eliminated by distributive-law rewrites within the deep structure of the text diagram \emph  {before translation into circuits}. Note that what is meant by \emph  {distributive} here is, in string-diagrammatic terms, precisely the same as that in algebra, for expressions such as $a \times (b + c) = (a \times b) + (a \times c)$. A new copy-node for verb labels that has rewrites for all verbs facilitates distribution, and the deep \texttt  {and} nodes come in a tensor-dentensor pair analogous to those for nonstrict string diagrams \begin  {color}{red}CITE \end  {color}\xspace  . Sources of rewrites are outlined in dashed boxes. }}{7}{subsection.1.1.1}\protected@file@percent }
\newpmemlabel{^_4}{8}
\newpmemlabel{^_5}{8}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces  \begin  {example}[\textbf  {Syncategorematicity II}] \[\texttt  {Bob drinks \underline  {and} smokes}\] \end  {example} In this example, the same word \texttt  {and} is a conjunction of verbs. In this case we choose to interpret the conjunction of verbs as sequential composition, so there is no need for a corresponding detensor for the \texttt  {and} of verbs. }}{8}{theorem.1.1.1}\protected@file@percent }
\newpmemlabel{^_6}{8}
\newpmemlabel{^_7}{8}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces  \begin  {example}[\textbf  {Coordination}] \[\texttt  {Alice \underline  {and} Bob drink beer \underline  {and} wine \underline  {respectively}}\] \end  {example} We stand to win in terms of conceptual economy for modelling; more complex phenomena of text structure such as coordination appear to be resolvable in the same framework of distributivity-law rewrites. }}{8}{theorem.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Avenues II: determiners and quantifiers in context}{8}{subsection.1.1.2}\protected@file@percent }
\newpmemlabel{^_8}{9}
\newpmemlabel{^_9}{9}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces  \begin  {example}[\textbf  {Determiners I}] \[\texttt  {Bob drinks \underline  {the} beer} \text  { (among drinks)}\] \end  {example} Here, \texttt  {drinks} is considered transitive and \texttt  {the beer} a nesting box for \texttt  {drinks} that reaches over to contextual wires representing a selection of beverages. In this case (relying on the implicit uniqueness of \texttt  {the}), a series of \texttt  {beer?} tests may be computed, and the best match chosen as the resulting argument for \texttt  {drinks}. }}{9}{subsection.1.1.2}\protected@file@percent }
\newpmemlabel{^_10}{9}
\newpmemlabel{^_11}{9}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces  \begin  {example}[\textbf  {Determiners II}] \[\texttt  {Bob drinks \underline  {a} beer} \text  { (among drinks)}\] \end  {example} We take the logical (and pragmatic) reading of \texttt  {a} as $\exists ! x: \texttt  {beer?}(x) \wedge \texttt  {drinks?}(\texttt  {Bob},x)$. Subject to having a method to hold onto alternatives -- in essence an inquisitive semantics approach -- we may create alternative circuits for each successful \texttt  {beer?} test. }}{9}{theorem.1.1.4}\protected@file@percent }
\newlabel{ex:beer2}{{1.5}{9}{Avenues II: determiners and quantifiers in context}{theorem.1.1.5}{}}
\newpmemlabel{^_12}{10}
\newpmemlabel{^_13}{10}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces  \begin  {example}[\textbf  {Determiners III}] \[\texttt  {Bob drinks \underline  {a} beer} \text  { (that we didn't know about)}\] \end  {example} When there are no beers in context, the same statement takes on a dynamic reading: it constitutes the introduction of a beer into discourse. In terms of text circuits, this amounts to introducing a novel beer-state and beer-wire. Determining an appropriate setting to accommodate "arbitrary" vs. "concrete" beers (c.f. Fine's arbitrary objects \begin  {color}{red}CITE \end  {color}\xspace  ) requires further research and experimentation, but preliminarily it is known that density matrices are capable of modelling semantic entailment \begin  {color}{red}CITE \end  {color}\xspace  , at the computational cost of adopting the kronecker product. This diagram doesn't typecheck, but note that it doesn't have to, because our strategy for evaluation of determiners treats circuits as syntactic objects to be manipulated. }}{10}{theorem.1.1.5}\protected@file@percent }
\newpmemlabel{^_14}{10}
\newpmemlabel{^_15}{10}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces  \begin  {example}[\textbf  {Quantifiers I}] \[\texttt  {Bob drinks \underline  {all the beers}} \text  { (in context)}\] \end  {example} In a finitary context, drinking \texttt  {all the beers} amounts to applying the distributivity of \texttt  {and} iteratively in that context. In this case, \texttt  {all the beers} is treated as a reference-in-context to \texttt  {Hells} and \texttt  {Duvel}. In the same manner, existential quantifiers in finite contexts can be treated as finitary disjunctions, which is handled by creating alternative circuits, as in Example \ref  {ex:beer2} }}{10}{theorem.1.1.6}\protected@file@percent }
\newpmemlabel{^_16}{11}
\newpmemlabel{^_17}{11}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces  \begin  {example}[\textbf  {Quantifiers II}] \[\texttt  {Bob drinks \underline  {all} beers} \text  { (generic)}\] \end  {example} Without the determiner \texttt  {the}, this becomes a generic statement, which logically amounts to (analysing the usual conditional as a disjunction) $\forall x: \neg \texttt  {beer?}(x) \vee \texttt  {drinks?}(\texttt  {Bob},x)$. We can treat generic universal quantifiers of this kind in at least two ways. The first essentially truth-conditional approach is to treat the generic as a process-theoretic condition governing measurements: whenever it is the case that something is a beer, it is the case that Bob drinks it. The second "inferential" appraoch is to treat the generic as a rewrite of text circuits conditioned on a beer test: whenever something is a beer we may add on a gate witnessing that Bob drinks that beverage. }}{11}{theorem.1.1.7}\protected@file@percent }
\ttl@finishall
\gdef \@abspage@last{11}
