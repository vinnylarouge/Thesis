
@article{joyal_geometry_1991,
	title = {The geometry of tensor calculus, {I}},
	volume = {88},
	issn = {0001-8708},
	url = {https://www.sciencedirect.com/science/article/pii/000187089190003P},
	doi = {10.1016/0001-8708(91)90003-P},
	abstract = {A coherent presentation of an n-category is a presentation by generators, relations and relations among relations. Confluent and terminating rewriting systems generate coherent presentations, whose relations among relations are defined by confluence diagrams of critical branchings. This article introduces a procedure to compute coherent presentations when the rewrite relations are defined modulo a set of axioms. Our coherence results are formulated using the structure of n-categories enriched in double groupoids, whose horizontal cells represent rewriting paths, vertical cells represent the congruence generated by the axioms and square cells represent coherence cells induced by diagrams of confluence modulo. We illustrate our constructions on rewriting systems modulo commutation relations in commutative monoids, isotopy relations in pivotal monoidal categories, and inverse relations in groups.},
	language = {en},
	number = {1},
	urldate = {2023-01-18},
	journal = {Advances in Mathematics},
	author = {Joyal, Andr√© and Street, Ross},
	month = jul,
	year = {1991},
	pages = {55--112},
	file = {ScienceDirect Full Text PDF:/Users/vincent/Zotero/storage/4KAWLMQF/Joyal and Street - 1991 - The geometry of tensor calculus, I.pdf:application/pdf},
}

@article{maclane_natural_1963,
	title = {Natural {Associativity} and {Commutativity}},
	volume = {49},
	copyright = {All rights reserved by Rice University. This work is licensed under a Creative Commons Attribution Non-commercial 4.0 License.},
	url = {https://scholarship.rice.edu/handle/1911/62865},
	abstract = {Paper presented in three lectures in Anderson Hall on September 23, 24, 26, 1963},
	language = {eng},
	number = {4},
	urldate = {2023-01-18},
	journal = {Rice Institute Pamphlet - Rice University Studies},
	author = {MacLane, Saunders},
	month = oct,
	year = {1963},
	note = {Accepted: 2011-11-08T19:13:47Z
Publisher: Rice University},
	file = {Full Text PDF:/Users/vincent/Zotero/storage/2BCIIAN5/MacLane - 1963 - Natural Associativity and Commutativity.pdf:application/pdf},
}

@book{lane_categories_2010,
	address = {New York, NY},
	edition = {2nd ed. 1978. Softcover reprint of the original 2nd ed. 1978 edition},
	title = {Categories for the {Working} {Mathematician}: 5},
	isbn = {978-1-4419-3123-8},
	shorttitle = {Categories for the {Working} {Mathematician}},
	abstract = {An array of general ideas useful in a wide variety of fields. Starting from the foundations, this book illuminates the concepts of category, functor, natural transformation, and duality. It then turns to adjoint functors, which provide a description of universal constructions, an analysis of the representations of functors by sets of morphisms, and a means of manipulating direct and inverse limits. These categorical concepts are extensively illustrated in the remaining chapters, which include many applications of the basic existence theorem for adjoint functors. The categories of algebraic systems are constructed from certain adjoint-like data and characterised by Beck's theorem. After considering a variety of applications, the book continues with the construction and exploitation of Kan extensions. This second edition includes a number of revisions and additions, including new chapters on topics of active interest: symmetric monoidal categories and braided monoidal categories, and the coherence theorems for them, as well as 2-categories and the higher dimensional categories which have recently come into prominence.},
	language = {English},
	publisher = {Springer},
	author = {Lane, Saunders Mac},
	month = nov,
	year = {2010},
}

@incollection{selinger_survey_2010,
	title = {A survey of graphical languages for monoidal categories},
	volume = {813},
	url = {http://arxiv.org/abs/0908.3347},
	abstract = {This article is intended as a reference guide to various notions of monoidal categories and their associated string diagrams. It is hoped that this will be useful not just to mathematicians, but also to physicists, computer scientists, and others who use diagrammatic reasoning. We have opted for a somewhat informal treatment of topological notions, and have omitted most proofs. Nevertheless, the exposition is sufficiently detailed to make it clear what is presently known, and to serve as a starting place for more in-depth study. Where possible, we provide pointers to more rigorous treatments in the literature. Where we include results that have only been proved in special cases, we indicate this in the form of caveats.},
	urldate = {2023-01-18},
	author = {Selinger, Peter},
	year = {2010},
	doi = {10.1007/978-3-642-12821-9_4},
	note = {arXiv:0908.3347 [math]},
	keywords = {18D10, Mathematics - Category Theory},
	pages = {289--355},
	file = {arXiv Fulltext PDF:/Users/vincent/Zotero/storage/C64L57Z9/Selinger - 2010 - A survey of graphical languages for monoidal categ.pdf:application/pdf;arXiv.org Snapshot:/Users/vincent/Zotero/storage/DNLSM8N6/0908.html:text/html},
}

@misc{mahowald_dissociating_2023,
	title = {Dissociating language and thought in large language models: a cognitive perspective},
	shorttitle = {Dissociating language and thought in large language models},
	url = {http://arxiv.org/abs/2301.06627},
	doi = {10.48550/arXiv.2301.06627},
	abstract = {Today's large language models (LLMs) routinely generate coherent, grammatical and seemingly meaningful paragraphs of text. This achievement has led to speculation that these networks are -- or will soon become -- "thinking machines", capable of performing tasks that require abstract knowledge and reasoning. Here, we review the capabilities of LLMs by considering their performance on two different aspects of language use: 'formal linguistic competence', which includes knowledge of rules and patterns of a given language, and 'functional linguistic competence', a host of cognitive abilities required for language understanding and use in the real world. Drawing on evidence from cognitive neuroscience, we show that formal competence in humans relies on specialized language processing mechanisms, whereas functional competence recruits multiple extralinguistic capacities that comprise human thought, such as formal reasoning, world knowledge, situation modeling, and social cognition. In line with this distinction, LLMs show impressive (although imperfect) performance on tasks requiring formal linguistic competence, but fail on many tests requiring functional competence. Based on this evidence, we argue that (1) contemporary LLMs should be taken seriously as models of formal linguistic skills; (2) models that master real-life language use would need to incorporate or develop not only a core language module, but also multiple non-language-specific cognitive capacities required for modeling thought. Overall, a distinction between formal and functional linguistic competence helps clarify the discourse surrounding LLMs' potential and provides a path toward building models that understand and use language in human-like ways.},
	urldate = {2023-01-19},
	publisher = {arXiv},
	author = {Mahowald, Kyle and Ivanova, Anna A. and Blank, Idan A. and Kanwisher, Nancy and Tenenbaum, Joshua B. and Fedorenko, Evelina},
	month = jan,
	year = {2023},
	note = {arXiv:2301.06627 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	annote = {Comment: The two lead authors contributed equally to this work},
	file = {arXiv Fulltext PDF:/Users/vincent/Zotero/storage/53W2J3J3/Mahowald et al. - 2023 - Dissociating language and thought in large languag.pdf:application/pdf;arXiv.org Snapshot:/Users/vincent/Zotero/storage/YBVKBY2B/2301.html:text/html},
}

@misc{epsilon3141_llms_2023,
	type = {Tweet},
	title = {{LLMs} + {RL} resolve failure modes},
	url = {https://twitter.com/epsilon3141/status/1615765147896918021?s=46&t=sZSAwsDNorcRseYgc_HpZg},
	journal = {Twitter},
	author = {{@epsilon3141}},
	month = jan,
	year = {2023},
}

@misc{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	doi = {10.48550/arXiv.1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2023-01-19},
	publisher = {arXiv},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = dec,
	year = {2017},
	note = {arXiv:1706.03762 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: 15 pages, 5 figures},
	file = {arXiv Fulltext PDF:/Users/vincent/Zotero/storage/AKW3XN6W/Vaswani et al. - 2017 - Attention Is All You Need.pdf:application/pdf;arXiv.org Snapshot:/Users/vincent/Zotero/storage/VF7K6WGC/1706.html:text/html},
}

@misc{bastian_google_2022,
	title = {Google {PaLM}: {Giant} language {AI} can explain jokes},
	shorttitle = {Google {PaLM}},
	url = {https://the-decoder.com/google-palm-giant-language-ai-can-explain-jokes/},
	abstract = {Google unveils the latest advance in artificial intelligence: The PaLM language AI model is huge, powerful, and the first building block of a grand vision.},
	language = {en-US},
	urldate = {2023-01-19},
	journal = {THE DECODER},
	author = {Bastian, Matthias},
	month = apr,
	year = {2022},
	file = {Snapshot:/Users/vincent/Zotero/storage/UTTV9Q44/google-palm-giant-language-ai-can-explain-jokes.html:text/html},
}

@techreport{andre_joyal_braided_1986,
	type = {Research {Report}},
	title = {Braided {Monoidal} {Categories}},
	url = {http://web.science.mq.edu.au/~street/JS1.pdf},
	number = {860081},
	urldate = {2023-01-18},
	institution = {MacQuarie University, School of Mathematics and Physics},
	author = {{Andr√© Joyal} and {Ross Street}},
	year = {1986},
	pages = {54},
	file = {JS1.pdf:/Users/vincent/Zotero/storage/4WHVIJ8C/JS1.pdf:application/pdf},
}

@misc{openai_chatgpt_2022,
	title = {{ChatGPT}: {Optimizing} {Language} {Models} for {Dialogue}},
	shorttitle = {{ChatGPT}},
	url = {https://openai.com/blog/chatgpt/},
	abstract = {We‚Äôve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests. ChatGPT is a sibling model to InstructGPT, which is trained to follow an instruction in},
	language = {en},
	urldate = {2023-01-19},
	journal = {OpenAI},
	author = {{OpenAI}},
	month = nov,
	year = {2022},
	file = {Snapshot:/Users/vincent/Zotero/storage/BP6WLSHY/chatgpt.html:text/html},
}

@article{church_pendulum_2011,
	title = {A {Pendulum} {Swung} {Too} {Far}},
	volume = {6},
	issn = {1945-3604},
	url = {https://journals.colorado.edu/index.php/lilt/article/view/1245},
	doi = {10.33011/lilt.v6i.1245},
	abstract = {Today's students might be faced with a very different set of challenges from those of the 1990s in the not-too-distant future. What should they do when most of the low hanging fruit has been pretty much picked over? 
In the particular case of Machine Translation, the revival of statistical approaches (e.g., Brown et al. (1993)) started out with finite-state methods for pragmatic reasons, but gradually over time, researchers have become more and more receptive to the use of syntax to capture long-distance dependences, especially when there isn't very much parallel corpora, and for language pairs with very different word orders (e.g., translating between a subject-verb-object (SVO) language like English and a verb final language like Japanese). Going forward, we should expect Machine Translation research to make more and more use of richer and richer linguistic representations. So too, there will soon be a day when stress will become important for speech recognition. 
Since it isn't possible for textbooks in computational linguistics to cover all of these topics, we should work with colleagues in other departments to make sure that students receive an education that is broad enough to prepare them for all possible futures, or at least all probable futures.},
	language = {en},
	urldate = {2023-01-19},
	journal = {Linguistic Issues in Language Technology},
	author = {Church, Kenneth},
	month = oct,
	year = {2011},
	file = {Church - 2011 - A Pendulum Swung Too Far.pdf:/Users/vincent/Zotero/storage/U2XHJME7/Church - 2011 - A Pendulum Swung Too Far.pdf:application/pdf},
}

@article{anderson_end_2008,
	title = {The {End} of {Theory}: {The} {Data} {Deluge} {Makes} the {Scientific} {Method} {Obsolete}},
	issn = {1059-1028},
	shorttitle = {The {End} of {Theory}},
	url = {https://www.wired.com/2008/06/pb-theory/},
	abstract = {Illustration: Marian Bantjes ‚ÄúAll models are wrong, but some are useful.‚Äù So proclaimed statistician George Box 30 years ago, and he was right. But what choice did we have? Only models, from cosmological equations to theories of human behavior, seemed to be able to consistently, if imperfectly, explain the world around us. Until now. Today companies [‚Ä¶]},
	language = {en-US},
	urldate = {2023-01-19},
	journal = {Wired},
	author = {Anderson, Chris},
	year = {2008},
	note = {Section: tags},
	keywords = {discoveries, magazine-16.07},
	file = {Snapshot:/Users/vincent/Zotero/storage/A63TD3EK/pb-theory.html:text/html},
}

@book{pietsch_epistemology_2022,
	address = {Cham},
	series = {Philosophical {Studies} {Series}},
	title = {On the {Epistemology} of {Data} {Science}: {Conceptual} {Tools} for a {New} {Inductivism}},
	volume = {148},
	isbn = {978-3-030-86441-5 978-3-030-86442-2},
	shorttitle = {On the {Epistemology} of {Data} {Science}},
	url = {https://link.springer.com/10.1007/978-3-030-86442-2},
	language = {en},
	urldate = {2023-01-19},
	publisher = {Springer International Publishing},
	author = {Pietsch, Wolfgang},
	year = {2022},
	doi = {10.1007/978-3-030-86442-2},
	keywords = {Causal approach to analogy, Causation difference making, data science analogy, Data science and explanation, data science causation, data science epistemology, Data science exploratory experimentation, data science inductivist framework, data science inductivist methodology, Data science phenomenological science, data science probability, data science theory, data science theory-driven experimentation, Epistemology of data science, Federica Russo inductive methodology, foundations of data science, Refining eliminative induction, Symmetries in probabilistic reasoning, Variational approach to induction},
	file = {Submitted Version:/Users/vincent/Zotero/storage/EWIBC7EJ/Pietsch - 2022 - On the Epistemology of Data Science Conceptual To.pdf:application/pdf},
}

@article{desai_epistemological_2022,
	title = {The epistemological foundations of data science: a critical analysis},
	issn = {1556-5068},
	shorttitle = {The epistemological foundations of data science},
	url = {https://www.ssrn.com/abstract=4008316},
	doi = {10.2139/ssrn.4008316},
	abstract = {The modern abundance and prominence of data has led to the development of ‚Äúdata science‚Äù as a new field of enquiry, along with a body of epistemological reflections upon its foundations, methods, and consequences. This article provides a systematic analysis and critical review of significant open problems and debates in the epistemology of data science. We propose a partition of the epistemology of data science into the following five domains: (i) the constitution of data science; (ii) the kind of enquiry that it identifies; (iii) the kinds of knowledge that data science generates; (iv) the nature and epistemological significance of ‚Äúblack box‚Äù problems; and (v) the relationship between data science and the philosophy of science more generally.},
	language = {en},
	urldate = {2023-01-19},
	journal = {SSRN Electronic Journal},
	author = {Desai, Jules and Watson, David and Wang, Vincent and Taddeo, Mariarosaria and Floridi, Luciano},
	year = {2022},
	file = {Desai et al. - 2022 - The epistemological foundations of data science a.pdf:/Users/vincent/Zotero/storage/RTR8JBXW/Desai et al. - 2022 - The epistemological foundations of data science a.pdf:application/pdf},
}

@misc{deleted_user_stack_2018,
	type = {Reddit {Post}},
	title = {{StAcK} {MoRe} {LaYeRs}},
	url = {www.reddit.com/r/ProgrammerHumor/comments/8c1i45/stack_more_layers/},
	urldate = {2023-01-19},
	journal = {r/ProgrammerHumor},
	author = {{(deleted user)}},
	month = apr,
	year = {2018},
}

@book{mcshane_linguistics_2021,
	title = {Linguistics for the {Age} of {AI}},
	url = {https://direct.mit.edu/books/book/5042/Linguistics-for-the-Age-of-AI},
	abstract = {A human-inspired, linguistically sophisticated model of language understanding for intelligent agent systems.The open access edition of this book was made possi},
	language = {en},
	urldate = {2023-01-19},
	author = {McShane, Marjorie and Nirenburg, Sergei},
	month = mar,
	year = {2021},
	doi = {10.7551/mitpress/13618.001.0001},
	file = {Snapshot:/Users/vincent/Zotero/storage/X5B9Z9D7/Linguistics-for-the-Age-of-AI.html:text/html},
}

@article{searle_minds_1980,
	title = {Minds, brains, and programs},
	volume = {3},
	issn = {1469-1825, 0140-525X},
	url = {https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/minds-brains-and-programs/DC644B47A4299C637C89772FACC2706A},
	doi = {10.1017/S0140525X00005756},
	abstract = {This article can be viewed as an attempt to explore the consequences of two propositions. (1) Intentionality in human beings (and animals) is a product of causal features of the brain. I assume this is an empirical fact about the actual causal relations between mental processes and brains. It says simply that certain brain processes are sufficient for intentionality. (2) Instantiating a computer program is never by itself a sufficient condition of intentionality. The main argument of this paper is directed at establishing this claim. The form of the argument is to show how a human agent could instantiate the program and still not have the relevant intentionality. These two propositions have the following consequences: (3) The explanation of how the brain produces intentionality cannot be that it does it by instantiating a computer program. This is a strict logical consequence of 1 and 2. (4) Any mechanism capable of producing intentionality must have causal powers equal to those of the brain. This is meant to be a trivial consequence of 1. (5) Any attempt literally to create intentionality artificially (strong AI) could not succeed just by designing programs but would have to duplicate the causal powers of the human brain. This follows from 2 and 4.‚ÄúCould a machine think?‚Äù On the argument advanced here only a machine could think, and only very special kinds of machines, namely brains and machines with internal causal powers equivalent to those of brains. And that is why strong AI has little to tell us about thinking, since it is not about machines but about programs, and no program by itself is sufficient for thinking.},
	language = {en},
	number = {3},
	urldate = {2023-01-19},
	journal = {Behavioral and Brain Sciences},
	author = {Searle, John R.},
	month = sep,
	year = {1980},
	note = {Publisher: Cambridge University Press},
	keywords = {artificial intelligence, brain, intentionality, mind},
	pages = {417--424},
}

@inproceedings{bender_climbing_2020,
	address = {Online},
	title = {Climbing towards {NLU}: {On} {Meaning}, {Form}, and {Understanding} in the {Age} of {Data}},
	shorttitle = {Climbing towards {NLU}},
	url = {https://www.aclweb.org/anthology/2020.acl-main.463},
	doi = {10.18653/v1/2020.acl-main.463},
	abstract = {The success of the large neural language models on many NLP tasks is exciting. However, we Ô¨Ånd that these successes sometimes lead to hype in which these models are being described as ‚Äúunderstanding‚Äù language or capturing ‚Äúmeaning‚Äù. In this position paper, we argue that a system trained only on form has a priori no way to learn meaning. In keeping with the ACL 2020 theme of ‚ÄúTaking Stock of Where We‚Äôve Been and Where We‚Äôre Going‚Äù, we argue that a clear understanding of the distinction between form and meaning will help guide the Ô¨Åeld towards better science around natural language understanding.},
	language = {en},
	urldate = {2023-01-19},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Bender, Emily M. and Koller, Alexander},
	year = {2020},
	pages = {5185--5198},
	file = {Bender and Koller - 2020 - Climbing towards NLU On Meaning, Form, and Unders.pdf:/Users/vincent/Zotero/storage/A7EIVDQ6/Bender and Koller - 2020 - Climbing towards NLU On Meaning, Form, and Unders.pdf:application/pdf},
}

@misc{teddy_teddynpc_i_2022,
	type = {Tweet},
	title = {I made {ChatGPT} take a full {SAT} test. {Here}'s how it did: https://t.co/{734sPFU3HY}},
	url = {https://twitter.com/teddynpc/status/1598767389390573569},
	language = {en},
	urldate = {2023-01-19},
	journal = {Twitter},
	author = {{teddy [@teddynpc]}},
	month = dec,
	year = {2022},
	file = {Snapshot:/Users/vincent/Zotero/storage/UMCD32KE/1598767389390573569.html:text/html},
}

@misc{thompson_gpt-35_2022,
	title = {{GPT}-3.5 {IQ} testing using {Raven}‚Äôs {Progressive} {Matrices}},
	url = {https://lifearchitect.ai/ravens/},
	abstract = {üëã Hi, I‚Äôm Alan. I advise government and enterprise on post-2020 AI like OpenAI ChatGPT and Google PaLM. You definitely want to keep up with the AI revolution in 2023. Join thousands of my paid subscribers from places like Harvard, RAND, Microsoft AI, Google AI, and Pearson (Wechsler). Get The Memo. Alan D. Thompson December [‚Ä¶]},
	urldate = {2023-01-19},
	journal = {Dr Alan D. Thompson ‚Äì Life Architect},
	author = {Thompson, Alan D.},
	year = {2022},
	file = {Snapshot:/Users/vincent/Zotero/storage/9UPUISEN/ravens.html:text/html},
}

@misc{sergey_ivanov_sergeyi49013776_iq_2022,
	type = {Tweet},
	title = {{IQ} of {ChatGPT} is 83. {It} corresponds to low average. {Here} is where it failedüßµ1/11 https://t.co/{Lgm3muCTiR}},
	url = {https://twitter.com/SergeyI49013776/status/1598430479878856737},
	language = {en},
	urldate = {2023-01-19},
	journal = {Twitter},
	author = {{Sergey Ivanov [@SergeyI49013776]}},
	month = dec,
	year = {2022},
	file = {Snapshot:/Users/vincent/Zotero/storage/BNB6GPHE/1598430479878856737.html:text/html},
}

@misc{hendrycks_measuring_2021,
	title = {Measuring {Mathematical} {Problem} {Solving} {With} the {MATH} {Dataset}},
	url = {http://arxiv.org/abs/2103.03874},
	abstract = {Many intellectual endeavors require mathematical problem solving, but this skill remains beyond the capabilities of computers. To measure this ability in machine learning models, we introduce MATH, a new dataset of 12,500 challenging competition mathematics problems. Each problem in MATH has a full step-by-step solution which can be used to teach models to generate answer derivations and explanations. To facilitate future research and increase accuracy on MATH, we also contribute a large auxiliary pretraining dataset which helps teach models the fundamentals of mathematics. Even though we are able to increase accuracy on MATH, our results show that accuracy remains relatively low, even with enormous Transformer models. Moreover, we Ô¨Ånd that simply increasing budgets and model parameter counts will be impractical for achieving strong mathematical reasoning if scaling trends continue. While scaling Transformers is automatically solving most other text-based tasks, scaling is not currently solving MATH. To have more traction on mathematical problem solving we will likely need new algorithmic advancements from the broader research community.},
	language = {en},
	urldate = {2023-01-19},
	publisher = {arXiv},
	author = {Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
	month = nov,
	year = {2021},
	note = {arXiv:2103.03874 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: NeurIPS 2021. Code and the MATH dataset is available at https://github.com/hendrycks/math/},
	file = {Hendrycks et al. - 2021 - Measuring Mathematical Problem Solving With the MA.pdf:/Users/vincent/Zotero/storage/ERA3NP3Z/Hendrycks et al. - 2021 - Measuring Mathematical Problem Solving With the MA.pdf:application/pdf},
}

@misc{sutton_bitter_2019,
	title = {The {Bitter} {Lesson}},
	url = {http://www.incompleteideas.net/IncIdeas/BitterLesson.html},
	urldate = {2023-01-20},
	author = {Sutton, Richard},
	year = {2019},
	file = {The Bitter Lesson:/Users/vincent/Zotero/storage/4FG9PSA9/BitterLesson.html:text/html},
}

@book{floridi_fourth_2014,
	address = {New York ; Oxford},
	title = {The {Fourth} {Revolution}: {How} the {Infosphere} is {Reshaping} {Human} {Reality}},
	isbn = {978-0-19-960672-6},
	shorttitle = {The {Fourth} {Revolution}},
	abstract = {Who are we, and how do we relate to each other? Luciano Floridi, one of the leading figures in contemporary philosophy, argues that the explosive developments in Information and Communication Technologies (ICTs) is changing the answer to these fundamental human questions.  As the boundaries between life online and offline break down, and we become seamlessly connected to each other and surrounded by smart, responsive objects, we are all becoming integrated into an "infosphere". Personas we adopt in social media, for example, feed into our 'real' lives so that we begin to live, as Floridi puts in, "onlife". Following those led by Copernicus, Darwin, and Freud, this metaphysical shift represents nothing less than a fourth revolution.  "Onlife" defines more and more of our daily activity - the way we shop, work, learn, care for our health, entertain ourselves, conduct our relationships; the way we interact with the worlds of law, finance, and politics; even the way we conduct war. In every department of life, ICTs have become environmental forces which are creating and transforming our realities. How can we ensure that we shall reap their benefits? What are the implicit risks? Are our technologies going to enable and empower us, or constrain us? Floridi argues that we must expand our ecological and ethical approach to cover both natural and man-made realities, putting the 'e' in an environmentalism that can deal successfully with the new challenges posed by our digital technologies and information society.},
	language = {English},
	publisher = {OUP Oxford},
	author = {Floridi, Luciano},
	month = jun,
	year = {2014},
}

@misc{wei_chain--thought_2023,
	title = {Chain-of-{Thought} {Prompting} {Elicits} {Reasoning} in {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2201.11903},
	doi = {10.48550/arXiv.2201.11903},
	abstract = {We explore how generating a chain of thought -- a series of intermediate reasoning steps -- significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.},
	urldate = {2023-01-20},
	publisher = {arXiv},
	author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
	month = jan,
	year = {2023},
	note = {arXiv:2201.11903 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/vincent/Zotero/storage/5ENL4YH7/Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in La.pdf:application/pdf;arXiv.org Snapshot:/Users/vincent/Zotero/storage/ZDSVIHVH/2201.html:text/html},
}

@book{chomsky_new_2000,
	address = {Cambridge},
	title = {New {Horizons} in the {Study} of {Language} and {Mind}},
	isbn = {978-0-521-65147-9},
	url = {https://www.cambridge.org/core/books/new-horizons-in-the-study-of-language-and-mind/2CF4C469C8867CB0168F4B9D6EA8BF38},
	abstract = {This book is an outstanding contribution to the philosophical study of language and mind, by one of the most influential thinkers of our time. In a series of penetrating essays, Chomsky cuts through the confusion and prejudice which has infected the study of language and mind, bringing new solutions to traditional philosophical puzzles and fresh perspectives on issues of general interest, ranging from the mind-body problem to the unification of science. Using a range of imaginative and deceptively simple linguistic analyses, Chomsky defends the view that knowledge of language is internal to the human mind. He argues that a proper study of language must deal with this mental construct. According to Chomsky, therefore, human language is a 'biological object' and should be analyzed using the methodology of the sciences. His examples and analyses come together in this book to give a unique and compelling perspective on language and the mind.},
	urldate = {2023-01-20},
	publisher = {Cambridge University Press},
	author = {Chomsky, Noam},
	year = {2000},
	doi = {10.1017/CBO9780511811937},
	file = {Snapshot:/Users/vincent/Zotero/storage/AIU6RVDI/2CF4C469C8867CB0168F4B9D6EA8BF38.html:text/html;Submitted Version:/Users/vincent/Zotero/storage/GUXCSDZH/Chomsky - 2000 - New Horizons in the Study of Language and Mind.pdf:application/pdf},
}

@article{mollica_humans_2019,
	title = {Humans store about 1.5 megabytes of information during language acquisition},
	volume = {6},
	issn = {2054-5703},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6458406/},
	doi = {10.1098/rsos.181393},
	abstract = {We introduce theory-neutral estimates of the amount of information learners possess about how language works. We provide estimates at several levels of linguistic analysis: phonemes, wordforms, lexical semantics, word frequency and syntax. Our best guess is that the average English-speaking adult has learned 12.5 million bits of information, the majority of which is lexical semantics. Interestingly, very little of this information is syntactic, even in our upper bound analyses. Generally, our results suggest that learners possess remarkable inferential mechanisms capable of extracting, on average, nearly 2000 bits of information about how language works each day for 18 years.},
	number = {3},
	urldate = {2023-01-20},
	journal = {Royal Society Open Science},
	author = {Mollica, Francis and Piantadosi, Steven T.},
	month = mar,
	year = {2019},
	pmid = {31032001},
	pmcid = {PMC6458406},
	pages = {181393},
	file = {PubMed Central Full Text PDF:/Users/vincent/Zotero/storage/HDNUGTH6/Mollica and Piantadosi - 2019 - Humans store about 1.5 megabytes of information du.pdf:application/pdf},
}

@misc{tom_goldstein_tomgoldsteincs_training_2022,
	type = {Tweet},
	title = {Training {PaLM} takes 3.2 million kilowatt hours of power. {If} you powered {TPUs} by riding a bicycle, and you pedaled hard (nearly 400 watts), it would take you 1000 years to train {PaLM}, not including bathroom breaks. {In} that time, you'd make 320 trips around the globe!},
	url = {https://twitter.com/tomgoldsteincs/status/1544370734574731266},
	language = {en},
	urldate = {2023-01-20},
	journal = {Twitter},
	author = {{Tom Goldstein [@tomgoldsteincs]}},
	month = jul,
	year = {2022},
	file = {Snapshot:/Users/vincent/Zotero/storage/SPZBEDWA/1544370734574731266.html:text/html},
}

@misc{chowdhery_palm_2022,
	title = {{PaLM}: {Scaling} {Language} {Modeling} with {Pathways}},
	shorttitle = {{PaLM}},
	url = {http://arxiv.org/abs/2204.02311},
	doi = {10.48550/arXiv.2204.02311},
	abstract = {Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540-billion parameter, densely activated, Transformer language model, which we call Pathways Language Model PaLM. We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.},
	urldate = {2023-01-20},
	publisher = {arXiv},
	author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sasha and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
	month = oct,
	year = {2022},
	note = {arXiv:2204.02311 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/vincent/Zotero/storage/T8ZVZ885/Chowdhery et al. - 2022 - PaLM Scaling Language Modeling with Pathways.pdf:application/pdf;arXiv.org Snapshot:/Users/vincent/Zotero/storage/8JJTGGFC/2204.html:text/html},
}

@misc{khan_what_2023,
	title = {What are tokens and how to count them?},
	url = {https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them},
	language = {en},
	urldate = {2023-01-20},
	author = {Khan, Tabarak},
	year = {2023},
	file = {Snapshot:/Users/vincent/Zotero/storage/SSAK4BAD/4936856-what-are-tokens-and-how-to-count-them.html:text/html},
}

@article{herculano-houzel_remarkable_2012,
	title = {The remarkable, yet not extraordinary, human brain as a scaled-up primate brain and its associated cost},
	volume = {109 Suppl 1},
	issn = {1091-6490},
	doi = {10.1073/pnas.1201895109},
	abstract = {Neuroscientists have become used to a number of "facts" about the human brain: It has 100 billion neurons and 10- to 50-fold more glial cells; it is the largest-than-expected for its body among primates and mammals in general, and therefore the most cognitively able; it consumes an outstanding 20\% of the total body energy budget despite representing only 2\% of body mass because of an increased metabolic need of its neurons; and it is endowed with an overdeveloped cerebral cortex, the largest compared with brain size. These facts led to the widespread notion that the human brain is literally extraordinary: an outlier among mammalian brains, defying evolutionary rules that apply to other species, with a uniqueness seemingly necessary to justify the superior cognitive abilities of humans over mammals with even larger brains. These facts, with deep implications for neurophysiology and evolutionary biology, are not grounded on solid evidence or sound assumptions, however. Our recent development of a method that allows rapid and reliable quantification of the numbers of cells that compose the whole brain has provided a means to verify these facts. Here, I review this recent evidence and argue that, with 86 billion neurons and just as many nonneuronal cells, the human brain is a scaled-up primate brain in its cellular composition and metabolic cost, with a relatively enlarged cerebral cortex that does not have a relatively larger number of brain neurons yet is remarkable in its cognitive abilities and metabolism simply because of its extremely large number of neurons.},
	language = {eng},
	number = {Suppl 1},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Herculano-Houzel, Suzana},
	month = jun,
	year = {2012},
	pmid = {22723358},
	pmcid = {PMC3386878},
	keywords = {Animals, Biological Evolution, Brain, Humans, Nerve Net, Neuroglia, Neurons, Primates},
	pages = {10661--10668},
	file = {Full Text:/Users/vincent/Zotero/storage/PGHZV4MI/Herculano-Houzel - 2012 - The remarkable, yet not extraordinary, human brain.pdf:application/pdf},
}

@misc{narang_pathways_2022,
	title = {Pathways {Language} {Model} ({PaLM}): {Scaling} to 540 {Billion} {Parameters} for {Breakthrough} {Performance}},
	shorttitle = {Pathways {Language} {Model} ({PaLM})},
	url = {https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html},
	language = {en},
	urldate = {2023-01-20},
	author = {Narang, Sharan and Chowdhery, Aakanksha},
	year = {2022},
	file = {Snapshot:/Users/vincent/Zotero/storage/R8Y2MCK8/pathways-language-model-palm-scaling-to.html:text/html},
}
